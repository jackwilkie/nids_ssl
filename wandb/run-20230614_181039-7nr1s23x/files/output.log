
epoch = 0  |  train_loss = 0.107483  |  val_loss = 0.096003  |  training_for: 2.09
epoch = 1  |  train_loss = 0.107475  |  val_loss = 0.095981  |  training_for: 3.80
epoch = 2  |  train_loss = 0.107412  |  val_loss = 0.095937  |  training_for: 5.54
epoch = 3  |  train_loss = 0.107366  |  val_loss = 0.095884  |  training_for: 7.27
epoch = 4  |  train_loss = 0.107278  |  val_loss = 0.095811  |  training_for: 8.99
epoch = 5  |  train_loss = 0.107159  |  val_loss = 0.095712  |  training_for: 10.82
epoch = 6  |  train_loss = 0.107001  |  val_loss = 0.095591  |  training_for: 12.55
epoch = 7  |  train_loss = 0.106806  |  val_loss = 0.095440  |  training_for: 14.28
epoch = 8  |  train_loss = 0.106579  |  val_loss = 0.095259  |  training_for: 16.02
epoch = 9  |  train_loss = 0.106287  |  val_loss = 0.095033  |  training_for: 17.75
epoch = 10  |  train_loss = 0.105949  |  val_loss = 0.094758  |  training_for: 19.48
epoch = 11  |  train_loss = 0.105551  |  val_loss = 0.094423  |  training_for: 21.22
epoch = 12  |  train_loss = 0.105022  |  val_loss = 0.094026  |  training_for: 22.96
epoch = 13  |  train_loss = 0.104475  |  val_loss = 0.093541  |  training_for: 24.70
epoch = 14  |  train_loss = 0.103741  |  val_loss = 0.092994  |  training_for: 26.43
epoch = 15  |  train_loss = 0.102985  |  val_loss = 0.092382  |  training_for: 28.26
epoch = 16  |  train_loss = 0.102108  |  val_loss = 0.091714  |  training_for: 29.99
epoch = 17  |  train_loss = 0.101155  |  val_loss = 0.091009  |  training_for: 31.75
epoch = 18  |  train_loss = 0.100159  |  val_loss = 0.090294  |  training_for: 33.50
epoch = 19  |  train_loss = 0.099154  |  val_loss = 0.089610  |  training_for: 35.25
epoch = 20  |  train_loss = 0.098167  |  val_loss = 0.088983  |  training_for: 36.98
epoch = 21  |  train_loss = 0.097248  |  val_loss = 0.088438  |  training_for: 38.71
epoch = 22  |  train_loss = 0.096398  |  val_loss = 0.087957  |  training_for: 40.54
epoch = 23  |  train_loss = 0.095591  |  val_loss = 0.087560  |  training_for: 42.27
epoch = 24  |  train_loss = 0.094884  |  val_loss = 0.087223  |  training_for: 44.00
epoch = 25  |  train_loss = 0.094264  |  val_loss = 0.086913  |  training_for: 45.73
epoch = 26  |  train_loss = 0.093717  |  val_loss = 0.086652  |  training_for: 47.46
epoch = 27  |  train_loss = 0.093252  |  val_loss = 0.086414  |  training_for: 49.20
epoch = 28  |  train_loss = 0.092825  |  val_loss = 0.086200  |  training_for: 50.94
epoch = 29  |  train_loss = 0.092430  |  val_loss = 0.086034  |  training_for: 52.68
epoch = 30  |  train_loss = 0.092083  |  val_loss = 0.085933  |  training_for: 54.42
epoch = 31  |  train_loss = 0.091760  |  val_loss = 0.085862  |  training_for: 56.16
epoch = 32  |  train_loss = 0.091470  |  val_loss = 0.085899  |  training_for: 57.99
epoch = 33  |  train_loss = 0.091230  |  val_loss = 0.085937  |  training_for: 59.72
epoch = 34  |  train_loss = 0.091055  |  val_loss = 0.085924  |  training_for: 61.46
epoch = 35  |  train_loss = 0.090886  |  val_loss = 0.086003  |  training_for: 63.20
epoch = 36  |  train_loss = 0.090748  |  val_loss = 0.086041  |  training_for: 64.94
epoch = 37  |  train_loss = 0.090635  |  val_loss = 0.086106  |  training_for: 66.70
epoch = 38  |  train_loss = 0.090548  |  val_loss = 0.086242  |  training_for: 68.43
epoch = 39  |  train_loss = 0.090476  |  val_loss = 0.086295  |  training_for: 70.27
epoch = 40  |  train_loss = 0.090400  |  val_loss = 0.086316  |  training_for: 71.99
epoch = 41  |  train_loss = 0.090348  |  val_loss = 0.086352  |  training_for: 73.72
epoch = 42  |  train_loss = 0.090292  |  val_loss = 0.086412  |  training_for: 75.46
epoch = 43  |  train_loss = 0.090250  |  val_loss = 0.086372  |  training_for: 77.18
epoch = 44  |  train_loss = 0.090219  |  val_loss = 0.086497  |  training_for: 78.92
epoch = 45  |  train_loss = 0.090182  |  val_loss = 0.086476  |  training_for: 80.68
epoch = 46  |  train_loss = 0.090163  |  val_loss = 0.086620  |  training_for: 82.41
epoch = 47  |  train_loss = 0.090151  |  val_loss = 0.086628  |  training_for: 84.14
epoch = 48  |  train_loss = 0.090126  |  val_loss = 0.086802  |  training_for: 85.89
epoch = 49  |  train_loss = 0.090107  |  val_loss = 0.086732  |  training_for: 87.71
epoch = 50  |  train_loss = 0.090096  |  val_loss = 0.087113  |  training_for: 89.44
epoch = 51  |  train_loss = 0.090089  |  val_loss = 0.086814  |  training_for: 91.17
epoch = 52  |  train_loss = 0.090074  |  val_loss = 0.087122  |  training_for: 92.91
epoch = 53  |  train_loss = 0.090059  |  val_loss = 0.087194  |  training_for: 94.64
epoch = 54  |  train_loss = 0.090051  |  val_loss = 0.087099  |  training_for: 96.38
epoch = 55  |  train_loss = 0.090047  |  val_loss = 0.087461  |  training_for: 98.12
epoch = 56  |  train_loss = 0.090034  |  val_loss = 0.087101  |  training_for: 99.97
epoch = 57  |  train_loss = 0.090026  |  val_loss = 0.087446  |  training_for: 101.70
epoch = 58  |  train_loss = 0.090017  |  val_loss = 0.087471  |  training_for: 103.43
epoch = 59  |  train_loss = 0.090009  |  val_loss = 0.087491  |  training_for: 105.16
epoch = 60  |  train_loss = 0.089999  |  val_loss = 0.087561  |  training_for: 106.89
epoch = 61  |  train_loss = 0.089997  |  val_loss = 0.087646  |  training_for: 108.63
epoch = 62  |  train_loss = 0.089994  |  val_loss = 0.087576  |  training_for: 110.39
epoch = 63  |  train_loss = 0.089991  |  val_loss = 0.087630  |  training_for: 112.12
epoch = 64  |  train_loss = 0.089985  |  val_loss = 0.087792  |  training_for: 113.85
epoch = 65  |  train_loss = 0.089981  |  val_loss = 0.087681  |  training_for: 115.59
Traceback (most recent call last):
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 132, in <module>
    main()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 118, in main
    train(model = model,
  File "/home/jwilkie/code_base/packages/model_training/training_loops.py", line 150, in train
    loss = loss_calc(model, batch)  #compute validation loss
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/saint/composite_loss.py", line 45, in calc_loss
    z = model.feed(x)
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/saint/saint.py", line 138, in feed
    return self.encoder(self.embedding_layer(x))
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/encoders.py", line 55, in forward
    x = layer(x)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/encoders.py", line 104, in forward
    return self.sublayers[1](x, self.feed_forward)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/architecture.py", line 45, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/architecture.py", line 135, in forward
    return self.w2(self.dropout(self.activation(self.w1(x))))  # apply forward pass
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/utils/activations.py", line 36, in forward
    return x * self.activation(gates)
  File "/home/jwilkie/code_base/packages/utils/activations.py", line 54, in activation
    return F.silu(x)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/functional.py", line 2059, in silu
    return torch._C._nn.silu(input)
KeyboardInterrupt