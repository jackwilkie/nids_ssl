epoch = 0  |  train_loss = 0.163448  |  val_loss = 0.161914  |  training_for: 1.77
epoch = 1  |  train_loss = 0.154315  |  val_loss = 0.158463  |  training_for: 3.18
epoch = 2  |  train_loss = 0.151775  |  val_loss = 0.158748  |  training_for: 4.60
epoch = 3  |  train_loss = 0.150253  |  val_loss = 0.158961  |  training_for: 6.02
epoch = 4  |  train_loss = 0.149337  |  val_loss = 0.159093  |  training_for: 7.47
epoch = 5  |  train_loss = 0.148883  |  val_loss = 0.159698  |  training_for: 8.88
epoch = 6  |  train_loss = 0.148653  |  val_loss = 0.159143  |  training_for: 10.30
epoch = 7  |  train_loss = 0.148538  |  val_loss = 0.159066  |  training_for: 11.72
epoch = 8  |  train_loss = 0.148516  |  val_loss = 0.158975  |  training_for: 13.15
epoch = 9  |  train_loss = 0.148450  |  val_loss = 0.158797  |  training_for: 14.56
epoch = 10  |  train_loss = 0.148388  |  val_loss = 0.159014  |  training_for: 16.13
epoch = 11  |  train_loss = 0.148377  |  val_loss = 0.159062  |  training_for: 17.54
epoch = 12  |  train_loss = 0.148348  |  val_loss = 0.159051  |  training_for: 18.96
epoch = 13  |  train_loss = 0.148329  |  val_loss = 0.159269  |  training_for: 20.37
epoch = 14  |  train_loss = 0.148319  |  val_loss = 0.158844  |  training_for: 21.79
epoch = 15  |  train_loss = 0.148347  |  val_loss = 0.160180  |  training_for: 23.22
epoch = 16  |  train_loss = 0.148346  |  val_loss = 0.159121  |  training_for: 24.64
epoch = 17  |  train_loss = 0.148288  |  val_loss = 0.159711  |  training_for: 26.06
epoch = 18  |  train_loss = 0.148273  |  val_loss = 0.159439  |  training_for: 27.49
epoch = 19  |  train_loss = 0.148253  |  val_loss = 0.160546  |  training_for: 28.92
epoch = 20  |  train_loss = 0.148270  |  val_loss = 0.159172  |  training_for: 30.36
epoch = 21  |  train_loss = 0.148247  |  val_loss = 0.159733  |  training_for: 31.77
epoch = 22  |  train_loss = 0.148285  |  val_loss = 0.159794  |  training_for: 33.19
epoch = 23  |  train_loss = 0.148295  |  val_loss = 0.159605  |  training_for: 34.71
epoch = 24  |  train_loss = 0.148287  |  val_loss = 0.159235  |  training_for: 36.14
epoch = 25  |  train_loss = 0.148250  |  val_loss = 0.158979  |  training_for: 37.57
epoch = 26  |  train_loss = 0.148237  |  val_loss = 0.158875  |  training_for: 38.99
epoch = 27  |  train_loss = 0.148218  |  val_loss = 0.158420  |  training_for: 40.42
epoch = 28  |  train_loss = 0.148209  |  val_loss = 0.158999  |  training_for: 41.85
epoch = 29  |  train_loss = 0.148220  |  val_loss = 0.158490  |  training_for: 43.28
epoch = 30  |  train_loss = 0.148233  |  val_loss = 0.158427  |  training_for: 44.71
epoch = 31  |  train_loss = 0.148223  |  val_loss = 0.158230  |  training_for: 46.15
epoch = 32  |  train_loss = 0.148255  |  val_loss = 0.158105  |  training_for: 47.43
epoch = 33  |  train_loss = 0.148201  |  val_loss = 0.157512  |  training_for: 48.72
epoch = 34  |  train_loss = 0.148198  |  val_loss = 0.157876  |  training_for: 50.01
epoch = 35  |  train_loss = 0.148173  |  val_loss = 0.157749  |  training_for: 51.30
epoch = 36  |  train_loss = 0.148171  |  val_loss = 0.157915  |  training_for: 52.68
epoch = 37  |  train_loss = 0.148187  |  val_loss = 0.157738  |  training_for: 54.09
epoch = 38  |  train_loss = 0.148198  |  val_loss = 0.157939  |  training_for: 55.52
epoch = 39  |  train_loss = 0.148161  |  val_loss = 0.156609  |  training_for: 56.94
epoch = 40  |  train_loss = 0.148169  |  val_loss = 0.157657  |  training_for: 58.37
epoch = 41  |  train_loss = 0.148153  |  val_loss = 0.156089  |  training_for: 59.80
epoch = 42  |  train_loss = 0.148129  |  val_loss = 0.156984  |  training_for: 61.23
epoch = 43  |  train_loss = 0.148156  |  val_loss = 0.157154  |  training_for: 62.66
epoch = 44  |  train_loss = 0.148157  |  val_loss = 0.156792  |  training_for: 64.08
epoch = 45  |  train_loss = 0.148161  |  val_loss = 0.156817  |  training_for: 65.50
epoch = 46  |  train_loss = 0.148137  |  val_loss = 0.156223  |  training_for: 66.93
epoch = 47  |  train_loss = 0.148130  |  val_loss = 0.156393  |  training_for: 68.37
epoch = 48  |  train_loss = 0.148138  |  val_loss = 0.155843  |  training_for: 69.80
epoch = 49  |  train_loss = 0.148117  |  val_loss = 0.156201  |  training_for: 71.23
epoch = 50  |  train_loss = 0.148150  |  val_loss = 0.156699  |  training_for: 72.76
epoch = 51  |  train_loss = 0.148208  |  val_loss = 0.155739  |  training_for: 74.19
epoch = 52  |  train_loss = 0.148166  |  val_loss = 0.154864  |  training_for: 75.65
epoch = 53  |  train_loss = 0.148142  |  val_loss = 0.155557  |  training_for: 77.11
epoch = 54  |  train_loss = 0.148140  |  val_loss = 0.155347  |  training_for: 78.55
epoch = 55  |  train_loss = 0.148127  |  val_loss = 0.156251  |  training_for: 79.98
epoch = 56  |  train_loss = 0.148165  |  val_loss = 0.155501  |  training_for: 81.40
epoch = 57  |  train_loss = 0.148116  |  val_loss = 0.155617  |  training_for: 82.86
epoch = 58  |  train_loss = 0.148117  |  val_loss = 0.155572  |  training_for: 84.30
epoch = 59  |  train_loss = 0.148091  |  val_loss = 0.154449  |  training_for: 85.77
epoch = 60  |  train_loss = 0.148093  |  val_loss = 0.155864  |  training_for: 87.21
epoch = 61  |  train_loss = 0.148123  |  val_loss = 0.155412  |  training_for: 88.64
epoch = 62  |  train_loss = 0.148091  |  val_loss = 0.155295  |  training_for: 90.06
epoch = 63  |  train_loss = 0.148119  |  val_loss = 0.155731  |  training_for: 91.59
epoch = 64  |  train_loss = 0.148120  |  val_loss = 0.155344  |  training_for: 93.04
epoch = 65  |  train_loss = 0.148095  |  val_loss = 0.155463  |  training_for: 94.50
epoch = 66  |  train_loss = 0.148107  |  val_loss = 0.154671  |  training_for: 95.89
epoch = 67  |  train_loss = 0.148109  |  val_loss = 0.155438  |  training_for: 97.33
epoch = 68  |  train_loss = 0.148100  |  val_loss = 0.153926  |  training_for: 98.77
epoch = 69  |  train_loss = 0.148125  |  val_loss = 0.154438  |  training_for: 100.21
epoch = 70  |  train_loss = 0.148115  |  val_loss = 0.154219  |  training_for: 101.64
epoch = 71  |  train_loss = 0.148098  |  val_loss = 0.154392  |  training_for: 103.07
epoch = 72  |  train_loss = 0.148093  |  val_loss = 0.155383  |  training_for: 104.53
epoch = 73  |  train_loss = 0.148107  |  val_loss = 0.155051  |  training_for: 105.99
epoch = 74  |  train_loss = 0.148078  |  val_loss = 0.155607  |  training_for: 107.44
epoch = 75  |  train_loss = 0.148066  |  val_loss = 0.154853  |  training_for: 108.86
epoch = 76  |  train_loss = 0.148080  |  val_loss = 0.155341  |  training_for: 110.39
epoch = 77  |  train_loss = 0.148089  |  val_loss = 0.154551  |  training_for: 111.82
epoch = 78  |  train_loss = 0.148066  |  val_loss = 0.155336  |  training_for: 113.25
epoch = 79  |  train_loss = 0.148067  |  val_loss = 0.155168  |  training_for: 114.68
epoch = 80  |  train_loss = 0.148066  |  val_loss = 0.155181  |  training_for: 116.11
epoch = 81  |  train_loss = 0.148067  |  val_loss = 0.154909  |  training_for: 117.59
epoch = 82  |  train_loss = 0.148056  |  val_loss = 0.154914  |  training_for: 119.04
epoch = 83  |  train_loss = 0.148080  |  val_loss = 0.155492  |  training_for: 120.50
epoch = 84  |  train_loss = 0.148096  |  val_loss = 0.154997  |  training_for: 121.94
epoch = 85  |  train_loss = 0.148075  |  val_loss = 0.154741  |  training_for: 123.38
epoch = 86  |  train_loss = 0.148063  |  val_loss = 0.154685  |  training_for: 124.82
epoch = 87  |  train_loss = 0.148110  |  val_loss = 0.155253  |  training_for: 126.23
epoch = 88  |  train_loss = 0.148057  |  val_loss = 0.154533  |  training_for: 127.68
epoch = 89  |  train_loss = 0.148029  |  val_loss = 0.154567  |  training_for: 129.11
epoch = 90  |  train_loss = 0.148045  |  val_loss = 0.155446  |  training_for: 130.65
epoch = 91  |  train_loss = 0.148038  |  val_loss = 0.154905  |  training_for: 132.11
epoch = 92  |  train_loss = 0.148049  |  val_loss = 0.155530  |  training_for: 133.52
epoch = 93  |  train_loss = 0.148056  |  val_loss = 0.155219  |  training_for: 134.99
epoch = 94  |  train_loss = 0.148050  |  val_loss = 0.155224  |  training_for: 136.46
epoch = 95  |  train_loss = 0.148044  |  val_loss = 0.154700  |  training_for: 137.89
epoch = 96  |  train_loss = 0.148039  |  val_loss = 0.154501  |  training_for: 139.31
epoch = 97  |  train_loss = 0.148027  |  val_loss = 0.154628  |  training_for: 140.75
epoch = 98  |  train_loss = 0.148015  |  val_loss = 0.155123  |  training_for: 142.16
epoch = 99  |  train_loss = 0.148026  |  val_loss = 0.155271  |  training_for: 143.58
epoch = 100  |  train_loss = 0.148052  |  val_loss = 0.155366  |  training_for: 145.02
epoch = 101  |  train_loss = 0.148081  |  val_loss = 0.154644  |  training_for: 146.44
epoch = 102  |  train_loss = 0.148031  |  val_loss = 0.154872  |  training_for: 147.89
epoch = 103  |  train_loss = 0.148049  |  val_loss = 0.155082  |  training_for: 149.44
epoch = 104  |  train_loss = 0.148036  |  val_loss = 0.154958  |  training_for: 150.89
epoch = 105  |  train_loss = 0.148020  |  val_loss = 0.155384  |  training_for: 152.34
epoch = 106  |  train_loss = 0.148063  |  val_loss = 0.155089  |  training_for: 153.78
epoch = 107  |  train_loss = 0.148071  |  val_loss = 0.154637  |  training_for: 155.20
epoch = 108  |  train_loss = 0.148052  |  val_loss = 0.155172  |  training_for: 156.64
epoch = 109  |  train_loss = 0.148076  |  val_loss = 0.154474  |  training_for: 158.06
epoch = 110  |  train_loss = 0.148056  |  val_loss = 0.154983  |  training_for: 159.51
epoch = 111  |  train_loss = 0.148046  |  val_loss = 0.155078  |  training_for: 160.97
epoch = 112  |  train_loss = 0.148013  |  val_loss = 0.154692  |  training_for: 162.45
epoch = 113  |  train_loss = 0.148003  |  val_loss = 0.154646  |  training_for: 163.90
epoch = 114  |  train_loss = 0.148028  |  val_loss = 0.154581  |  training_for: 165.33
epoch = 115  |  train_loss = 0.148017  |  val_loss = 0.154411  |  training_for: 166.76
epoch = 116  |  train_loss = 0.147998  |  val_loss = 0.154704  |  training_for: 168.19
epoch = 117  |  train_loss = 0.147994  |  val_loss = 0.154725  |  training_for: 169.71
epoch = 118  |  train_loss = 0.147995  |  val_loss = 0.154635  |  training_for: 171.18
epoch = 119  |  train_loss = 0.148019  |  val_loss = 0.154287  |  training_for: 172.62
epoch = 120  |  train_loss = 0.148019  |  val_loss = 0.154815  |  training_for: 174.07
epoch = 121  |  train_loss = 0.148010  |  val_loss = 0.154596  |  training_for: 175.51
epoch = 122  |  train_loss = 0.148010  |  val_loss = 0.155130  |  training_for: 176.95
epoch = 123  |  train_loss = 0.147999  |  val_loss = 0.154512  |  training_for: 178.42
epoch = 124  |  train_loss = 0.148025  |  val_loss = 0.154790  |  training_for: 179.86
epoch = 125  |  train_loss = 0.148027  |  val_loss = 0.154474  |  training_for: 181.31
epoch = 126  |  train_loss = 0.148009  |  val_loss = 0.154975  |  training_for: 182.73
epoch = 127  |  train_loss = 0.148017  |  val_loss = 0.153804  |  training_for: 184.16
epoch = 128  |  train_loss = 0.148005  |  val_loss = 0.155002  |  training_for: 185.60
epoch = 129  |  train_loss = 0.147991  |  val_loss = 0.154426  |  training_for: 187.03
epoch = 130  |  train_loss = 0.148016  |  val_loss = 0.153909  |  training_for: 188.55
epoch = 131  |  train_loss = 0.148006  |  val_loss = 0.154881  |  training_for: 189.99
epoch = 132  |  train_loss = 0.148001  |  val_loss = 0.155192  |  training_for: 191.45
epoch = 133  |  train_loss = 0.148020  |  val_loss = 0.153971  |  training_for: 192.89
epoch = 134  |  train_loss = 0.148021  |  val_loss = 0.154910  |  training_for: 194.33
epoch = 135  |  train_loss = 0.148000  |  val_loss = 0.154017  |  training_for: 195.77
epoch = 136  |  train_loss = 0.148036  |  val_loss = 0.154358  |  training_for: 197.21
epoch = 137  |  train_loss = 0.148005  |  val_loss = 0.154036  |  training_for: 198.64
epoch = 138  |  train_loss = 0.147984  |  val_loss = 0.154198  |  training_for: 200.05
epoch = 139  |  train_loss = 0.147973  |  val_loss = 0.154073  |  training_for: 201.48
epoch = 140  |  train_loss = 0.148003  |  val_loss = 0.154416  |  training_for: 202.93
epoch = 141  |  train_loss = 0.147988  |  val_loss = 0.154201  |  training_for: 204.37
epoch = 142  |  train_loss = 0.147993  |  val_loss = 0.153991  |  training_for: 205.81
epoch = 143  |  train_loss = 0.147995  |  val_loss = 0.154259  |  training_for: 207.24
epoch = 144  |  train_loss = 0.147992  |  val_loss = 0.154541  |  training_for: 208.79
epoch = 145  |  train_loss = 0.148009  |  val_loss = 0.153921  |  training_for: 210.24
epoch = 146  |  train_loss = 0.147989  |  val_loss = 0.154248  |  training_for: 211.68
epoch = 147  |  train_loss = 0.147990  |  val_loss = 0.154759  |  training_for: 213.14
epoch = 148  |  train_loss = 0.148016  |  val_loss = 0.153903  |  training_for: 214.61
epoch = 149  |  train_loss = 0.148007  |  val_loss = 0.154300  |  training_for: 216.03
epoch = 150  |  train_loss = 0.147996  |  val_loss = 0.154835  |  training_for: 217.45
epoch = 151  |  train_loss = 0.147992  |  val_loss = 0.154091  |  training_for: 218.93
epoch = 152  |  train_loss = 0.147979  |  val_loss = 0.154358  |  training_for: 220.37
epoch = 153  |  train_loss = 0.147984  |  val_loss = 0.154560  |  training_for: 221.82
epoch = 154  |  train_loss = 0.148013  |  val_loss = 0.154292  |  training_for: 223.30
epoch = 155  |  train_loss = 0.147990  |  val_loss = 0.154194  |  training_for: 224.75
epoch = 156  |  train_loss = 0.147986  |  val_loss = 0.154537  |  training_for: 226.21
epoch = 157  |  train_loss = 0.147981  |  val_loss = 0.154257  |  training_for: 227.72
epoch = 158  |  train_loss = 0.147978  |  val_loss = 0.153842  |  training_for: 229.16
epoch = 159  |  train_loss = 0.147976  |  val_loss = 0.154819  |  training_for: 230.60
epoch = 160  |  train_loss = 0.147975  |  val_loss = 0.154441  |  training_for: 232.04
epoch = 161  |  train_loss = 0.147971  |  val_loss = 0.154691  |  training_for: 233.47
epoch = 162  |  train_loss = 0.147999  |  val_loss = 0.153361  |  training_for: 234.92
epoch = 163  |  train_loss = 0.147997  |  val_loss = 0.154853  |  training_for: 236.38
epoch = 164  |  train_loss = 0.148007  |  val_loss = 0.154849  |  training_for: 237.83
epoch = 165  |  train_loss = 0.147995  |  val_loss = 0.154235  |  training_for: 239.30
epoch = 166  |  train_loss = 0.147992  |  val_loss = 0.154343  |  training_for: 240.74
epoch = 167  |  train_loss = 0.147973  |  val_loss = 0.154553  |  training_for: 242.17
epoch = 168  |  train_loss = 0.147989  |  val_loss = 0.154132  |  training_for: 243.60
epoch = 169  |  train_loss = 0.147964  |  val_loss = 0.155495  |  training_for: 245.03
epoch = 170  |  train_loss = 0.147998  |  val_loss = 0.154547  |  training_for: 246.47
epoch = 171  |  train_loss = 0.147980  |  val_loss = 0.153894  |  training_for: 248.01
epoch = 172  |  train_loss = 0.147980  |  val_loss = 0.153623  |  training_for: 249.46
epoch = 173  |  train_loss = 0.147958  |  val_loss = 0.154037  |  training_for: 250.89
epoch = 174  |  train_loss = 0.147957  |  val_loss = 0.153972  |  training_for: 252.33
epoch = 175  |  train_loss = 0.147999  |  val_loss = 0.154159  |  training_for: 253.79
epoch = 176  |  train_loss = 0.148009  |  val_loss = 0.154459  |  training_for: 255.24
epoch = 177  |  train_loss = 0.147998  |  val_loss = 0.155117  |  training_for: 256.68
epoch = 178  |  train_loss = 0.147997  |  val_loss = 0.154075  |  training_for: 258.13
epoch = 179  |  train_loss = 0.147943  |  val_loss = 0.154000  |  training_for: 259.57
epoch = 180  |  train_loss = 0.147934  |  val_loss = 0.154201  |  training_for: 261.00
epoch = 181  |  train_loss = 0.147942  |  val_loss = 0.155129  |  training_for: 262.44
epoch = 182  |  train_loss = 0.147954  |  val_loss = 0.154203  |  training_for: 263.87
epoch = 183  |  train_loss = 0.147956  |  val_loss = 0.153850  |  training_for: 265.31
epoch = 184  |  train_loss = 0.147946  |  val_loss = 0.154510  |  training_for: 266.76
epoch = 185  |  train_loss = 0.147972  |  val_loss = 0.153824  |  training_for: 268.29
epoch = 186  |  train_loss = 0.147960  |  val_loss = 0.153940  |  training_for: 269.74
epoch = 187  |  train_loss = 0.147980  |  val_loss = 0.154048  |  training_for: 271.18
epoch = 188  |  train_loss = 0.147982  |  val_loss = 0.153567  |  training_for: 272.63
epoch = 189  |  train_loss = 0.147981  |  val_loss = 0.153799  |  training_for: 273.97
epoch = 190  |  train_loss = 0.147992  |  val_loss = 0.153960  |  training_for: 275.41
epoch = 191  |  train_loss = 0.147980  |  val_loss = 0.154303  |  training_for: 276.86
epoch = 192  |  train_loss = 0.147944  |  val_loss = 0.154171  |  training_for: 278.30
epoch = 193  |  train_loss = 0.147967  |  val_loss = 0.154479  |  training_for: 279.75
epoch = 194  |  train_loss = 0.147946  |  val_loss = 0.154642  |  training_for: 281.19
epoch = 195  |  train_loss = 0.147944  |  val_loss = 0.153746  |  training_for: 282.64
epoch = 196  |  train_loss = 0.147953  |  val_loss = 0.153478  |  training_for: 284.09
epoch = 197  |  train_loss = 0.147969  |  val_loss = 0.154421  |  training_for: 285.53
epoch = 198  |  train_loss = 0.147980  |  val_loss = 0.154146  |  training_for: 287.10
epoch = 199  |  train_loss = 0.147955  |  val_loss = 0.154371  |  training_for: 288.54
epoch = 200  |  train_loss = 0.147938  |  val_loss = 0.154167  |  training_for: 290.00
epoch = 201  |  train_loss = 0.147925  |  val_loss = 0.154229  |  training_for: 291.44
epoch = 202  |  train_loss = 0.147940  |  val_loss = 0.153823  |  training_for: 292.88
epoch = 203  |  train_loss = 0.147940  |  val_loss = 0.154137  |  training_for: 294.32
epoch = 204  |  train_loss = 0.147963  |  val_loss = 0.153401  |  training_for: 295.76
epoch = 205  |  train_loss = 0.147946  |  val_loss = 0.153375  |  training_for: 297.21
epoch = 206  |  train_loss = 0.147961  |  val_loss = 0.154299  |  training_for: 298.66
epoch = 207  |  train_loss = 0.147961  |  val_loss = 0.154111  |  training_for: 300.11
epoch = 208  |  train_loss = 0.147929  |  val_loss = 0.153886  |  training_for: 301.57
epoch = 209  |  train_loss = 0.147969  |  val_loss = 0.153473  |  training_for: 302.98
epoch = 210  |  train_loss = 0.147951  |  val_loss = 0.154295  |  training_for: 304.43
epoch = 211  |  train_loss = 0.147952  |  val_loss = 0.153929  |  training_for: 305.85
epoch = 212  |  train_loss = 0.147935  |  val_loss = 0.153910  |  training_for: 307.40
epoch = 213  |  train_loss = 0.147946  |  val_loss = 0.153598  |  training_for: 308.84
epoch = 214  |  train_loss = 0.147969  |  val_loss = 0.153914  |  training_for: 310.30
epoch = 215  |  train_loss = 0.147942  |  val_loss = 0.154511  |  training_for: 311.74
epoch = 216  |  train_loss = 0.147937  |  val_loss = 0.153521  |  training_for: 313.22
epoch = 217  |  train_loss = 0.147931  |  val_loss = 0.153636  |  training_for: 314.66
epoch = 218  |  train_loss = 0.147952  |  val_loss = 0.153297  |  training_for: 316.10
epoch = 219  |  train_loss = 0.147942  |  val_loss = 0.154509  |  training_for: 317.54
epoch = 220  |  train_loss = 0.147964  |  val_loss = 0.153540  |  training_for: 318.95
epoch = 221  |  train_loss = 0.147949  |  val_loss = 0.154179  |  training_for: 320.39
epoch = 222  |  train_loss = 0.147938  |  val_loss = 0.153932  |  training_for: 321.83
epoch = 223  |  train_loss = 0.147947  |  val_loss = 0.154066  |  training_for: 323.24
epoch = 224  |  train_loss = 0.147917  |  val_loss = 0.153681  |  training_for: 324.69
epoch = 225  |  train_loss = 0.147942  |  val_loss = 0.153230  |  training_for: 326.14
epoch = 226  |  train_loss = 0.147954  |  val_loss = 0.154043  |  training_for: 327.70
epoch = 227  |  train_loss = 0.147937  |  val_loss = 0.153785  |  training_for: 329.14
epoch = 228  |  train_loss = 0.147950  |  val_loss = 0.153690  |  training_for: 330.60
epoch = 229  |  train_loss = 0.147944  |  val_loss = 0.153926  |  training_for: 332.05
epoch = 230  |  train_loss = 0.147946  |  val_loss = 0.153785  |  training_for: 333.51
epoch = 231  |  train_loss = 0.147924  |  val_loss = 0.153731  |  training_for: 334.95
epoch = 232  |  train_loss = 0.147925  |  val_loss = 0.153736  |  training_for: 336.42
epoch = 233  |  train_loss = 0.147930  |  val_loss = 0.153739  |  training_for: 337.87
epoch = 234  |  train_loss = 0.147938  |  val_loss = 0.154337  |  training_for: 339.33
epoch = 235  |  train_loss = 0.147912  |  val_loss = 0.153790  |  training_for: 340.79
epoch = 236  |  train_loss = 0.147941  |  val_loss = 0.153623  |  training_for: 342.24
epoch = 237  |  train_loss = 0.147927  |  val_loss = 0.153596  |  training_for: 343.74
epoch = 238  |  train_loss = 0.147935  |  val_loss = 0.153958  |  training_for: 345.19
epoch = 239  |  train_loss = 0.147931  |  val_loss = 0.153691  |  training_for: 346.67
epoch = 240  |  train_loss = 0.147947  |  val_loss = 0.154199  |  training_for: 348.21
epoch = 241  |  train_loss = 0.147954  |  val_loss = 0.153481  |  training_for: 349.65
epoch = 242  |  train_loss = 0.147913  |  val_loss = 0.153321  |  training_for: 351.08
epoch = 243  |  train_loss = 0.147929  |  val_loss = 0.153458  |  training_for: 352.54
epoch = 244  |  train_loss = 0.147915  |  val_loss = 0.153627  |  training_for: 353.97
epoch = 245  |  train_loss = 0.147934  |  val_loss = 0.153281  |  training_for: 355.42
epoch = 246  |  train_loss = 0.147935  |  val_loss = 0.153674  |  training_for: 356.86
epoch = 247  |  train_loss = 0.147960  |  val_loss = 0.153591  |  training_for: 358.28
epoch = 248  |  train_loss = 0.147935  |  val_loss = 0.153699  |  training_for: 359.73
epoch = 249  |  train_loss = 0.147924  |  val_loss = 0.153332  |  training_for: 361.19
epoch = 250  |  train_loss = 0.147906  |  val_loss = 0.153838  |  training_for: 362.66
epoch = 251  |  train_loss = 0.147909  |  val_loss = 0.153472  |  training_for: 364.10
epoch = 252  |  train_loss = 0.147915  |  val_loss = 0.152773  |  training_for: 365.53
epoch = 253  |  train_loss = 0.147917  |  val_loss = 0.152679  |  training_for: 366.97
epoch = 254  |  train_loss = 0.147931  |  val_loss = 0.152933  |  training_for: 368.57
epoch = 255  |  train_loss = 0.147930  |  val_loss = 0.153639  |  training_for: 370.04
epoch = 256  |  train_loss = 0.147928  |  val_loss = 0.153558  |  training_for: 371.48
epoch = 257  |  train_loss = 0.147950  |  val_loss = 0.153393  |  training_for: 372.93
epoch = 258  |  train_loss = 0.147925  |  val_loss = 0.153357  |  training_for: 374.38
epoch = 259  |  train_loss = 0.147919  |  val_loss = 0.153250  |  training_for: 375.83
epoch = 260  |  train_loss = 0.147929  |  val_loss = 0.152651  |  training_for: 377.31
epoch = 261  |  train_loss = 0.147945  |  val_loss = 0.152936  |  training_for: 378.75
epoch = 262  |  train_loss = 0.147941  |  val_loss = 0.153104  |  training_for: 380.19
epoch = 263  |  train_loss = 0.147923  |  val_loss = 0.152994  |  training_for: 381.68
epoch = 264  |  train_loss = 0.147945  |  val_loss = 0.153148  |  training_for: 383.13
epoch = 265  |  train_loss = 0.147946  |  val_loss = 0.153171  |  training_for: 384.60
epoch = 266  |  train_loss = 0.147908  |  val_loss = 0.153266  |  training_for: 386.02
epoch = 267  |  train_loss = 0.147905  |  val_loss = 0.153021  |  training_for: 387.48
epoch = 268  |  train_loss = 0.147913  |  val_loss = 0.153295  |  training_for: 389.01
epoch = 269  |  train_loss = 0.147939  |  val_loss = 0.152971  |  training_for: 390.47
epoch = 270  |  train_loss = 0.147926  |  val_loss = 0.152346  |  training_for: 391.90
epoch = 271  |  train_loss = 0.147917  |  val_loss = 0.152142  |  training_for: 393.35
epoch = 272  |  train_loss = 0.147937  |  val_loss = 0.152698  |  training_for: 394.80
epoch = 273  |  train_loss = 0.147910  |  val_loss = 0.152724  |  training_for: 396.27
epoch = 274  |  train_loss = 0.147942  |  val_loss = 0.153665  |  training_for: 397.73
epoch = 275  |  train_loss = 0.147948  |  val_loss = 0.153354  |  training_for: 399.18
epoch = 276  |  train_loss = 0.147950  |  val_loss = 0.152899  |  training_for: 400.63
epoch = 277  |  train_loss = 0.147919  |  val_loss = 0.153097  |  training_for: 402.10
epoch = 278  |  train_loss = 0.147916  |  val_loss = 0.153227  |  training_for: 403.56
epoch = 279  |  train_loss = 0.147919  |  val_loss = 0.152958  |  training_for: 405.01
epoch = 280  |  train_loss = 0.147898  |  val_loss = 0.152810  |  training_for: 406.44
epoch = 281  |  train_loss = 0.147912  |  val_loss = 0.152554  |  training_for: 407.90
epoch = 282  |  train_loss = 0.147891  |  val_loss = 0.153223  |  training_for: 409.45
epoch = 283  |  train_loss = 0.147888  |  val_loss = 0.152502  |  training_for: 410.92
epoch = 284  |  train_loss = 0.147906  |  val_loss = 0.153892  |  training_for: 412.37
epoch = 285  |  train_loss = 0.147916  |  val_loss = 0.153049  |  training_for: 413.81
epoch = 286  |  train_loss = 0.147885  |  val_loss = 0.153194  |  training_for: 415.27
epoch = 287  |  train_loss = 0.147908  |  val_loss = 0.152451  |  training_for: 416.72
epoch = 288  |  train_loss = 0.147929  |  val_loss = 0.153289  |  training_for: 418.18
epoch = 289  |  train_loss = 0.147905  |  val_loss = 0.152873  |  training_for: 419.62
epoch = 290  |  train_loss = 0.147929  |  val_loss = 0.152830  |  training_for: 421.08
epoch = 291  |  train_loss = 0.147939  |  val_loss = 0.153431  |  training_for: 422.52
epoch = 292  |  train_loss = 0.147916  |  val_loss = 0.153272  |  training_for: 423.93
epoch = 293  |  train_loss = 0.147906  |  val_loss = 0.152166  |  training_for: 425.38
epoch = 294  |  train_loss = 0.147923  |  val_loss = 0.152275  |  training_for: 426.81
epoch = 295  |  train_loss = 0.147905  |  val_loss = 0.152380  |  training_for: 428.26
epoch = 296  |  train_loss = 0.147898  |  val_loss = 0.152403  |  training_for: 429.70
epoch = 297  |  train_loss = 0.147900  |  val_loss = 0.152959  |  training_for: 431.24
epoch = 298  |  train_loss = 0.147919  |  val_loss = 0.153065  |  training_for: 432.68
epoch = 299  |  train_loss = 0.147932  |  val_loss = 0.152402  |  training_for: 434.12
epoch = 300  |  train_loss = 0.147901  |  val_loss = 0.152985  |  training_for: 435.57
epoch = 301  |  train_loss = 0.147885  |  val_loss = 0.152463  |  training_for: 437.01
epoch = 302  |  train_loss = 0.147900  |  val_loss = 0.152964  |  training_for: 438.48
epoch = 303  |  train_loss = 0.147907  |  val_loss = 0.152887  |  training_for: 439.95
epoch = 304  |  train_loss = 0.147910  |  val_loss = 0.152816  |  training_for: 441.43
epoch = 305  |  train_loss = 0.147919  |  val_loss = 0.152707  |  training_for: 442.88
epoch = 306  |  train_loss = 0.147889  |  val_loss = 0.152654  |  training_for: 444.37
epoch = 307  |  train_loss = 0.147917  |  val_loss = 0.153284  |  training_for: 445.83
epoch = 308  |  train_loss = 0.147905  |  val_loss = 0.152995  |  training_for: 447.27
epoch = 309  |  train_loss = 0.147912  |  val_loss = 0.152289  |  training_for: 448.72
epoch = 310  |  train_loss = 0.147919  |  val_loss = 0.152796  |  training_for: 450.20
epoch = 311  |  train_loss = 0.147893  |  val_loss = 0.152487  |  training_for: 451.82
epoch = 312  |  train_loss = 0.147910  |  val_loss = 0.152661  |  training_for: 453.26
epoch = 313  |  train_loss = 0.147904  |  val_loss = 0.153081  |  training_for: 454.70
epoch = 314  |  train_loss = 0.147921  |  val_loss = 0.153168  |  training_for: 456.17
epoch = 315  |  train_loss = 0.147917  |  val_loss = 0.152935  |  training_for: 457.61
epoch = 316  |  train_loss = 0.147912  |  val_loss = 0.152499  |  training_for: 459.12
epoch = 317  |  train_loss = 0.147925  |  val_loss = 0.152404  |  training_for: 460.56
epoch = 318  |  train_loss = 0.147920  |  val_loss = 0.152299  |  training_for: 461.98
epoch = 319  |  train_loss = 0.147918  |  val_loss = 0.152037  |  training_for: 463.42
epoch = 320  |  train_loss = 0.147913  |  val_loss = 0.152058  |  training_for: 464.88
epoch = 321  |  train_loss = 0.147918  |  val_loss = 0.152157  |  training_for: 466.39
epoch = 322  |  train_loss = 0.147889  |  val_loss = 0.152582  |  training_for: 467.83
epoch = 323  |  train_loss = 0.147894  |  val_loss = 0.152890  |  training_for: 469.26
epoch = 324  |  train_loss = 0.147930  |  val_loss = 0.153061  |  training_for: 470.73
epoch = 325  |  train_loss = 0.147913  |  val_loss = 0.152868  |  training_for: 472.28
epoch = 326  |  train_loss = 0.147897  |  val_loss = 0.152773  |  training_for: 473.74
epoch = 327  |  train_loss = 0.147873  |  val_loss = 0.152404  |  training_for: 475.19
epoch = 328  |  train_loss = 0.147889  |  val_loss = 0.153085  |  training_for: 476.64
epoch = 329  |  train_loss = 0.147870  |  val_loss = 0.153038  |  training_for: 478.10
epoch = 330  |  train_loss = 0.147881  |  val_loss = 0.152346  |  training_for: 479.56
epoch = 331  |  train_loss = 0.147864  |  val_loss = 0.152835  |  training_for: 481.05
epoch = 332  |  train_loss = 0.147857  |  val_loss = 0.153036  |  training_for: 482.49
epoch = 333  |  train_loss = 0.147877  |  val_loss = 0.153054  |  training_for: 483.93
epoch = 334  |  train_loss = 0.147923  |  val_loss = 0.153047  |  training_for: 485.37
epoch = 335  |  train_loss = 0.147875  |  val_loss = 0.152971  |  training_for: 486.81
epoch = 336  |  train_loss = 0.147859  |  val_loss = 0.152944  |  training_for: 488.25
epoch = 337  |  train_loss = 0.147868  |  val_loss = 0.152529  |  training_for: 489.69
epoch = 338  |  train_loss = 0.147880  |  val_loss = 0.152881  |  training_for: 491.13
epoch = 339  |  train_loss = 0.147889  |  val_loss = 0.152910  |  training_for: 492.69
epoch = 340  |  train_loss = 0.147890  |  val_loss = 0.153257  |  training_for: 494.13
epoch = 341  |  train_loss = 0.147892  |  val_loss = 0.153208  |  training_for: 495.57
epoch = 342  |  train_loss = 0.147871  |  val_loss = 0.153042  |  training_for: 497.06
epoch = 343  |  train_loss = 0.147899  |  val_loss = 0.152546  |  training_for: 498.54
epoch = 344  |  train_loss = 0.147909  |  val_loss = 0.152495  |  training_for: 499.99
epoch = 345  |  train_loss = 0.147890  |  val_loss = 0.152178  |  training_for: 501.45
epoch = 346  |  train_loss = 0.147902  |  val_loss = 0.152221  |  training_for: 502.89
epoch = 347  |  train_loss = 0.147907  |  val_loss = 0.152606  |  training_for: 504.32
epoch = 348  |  train_loss = 0.147894  |  val_loss = 0.152910  |  training_for: 505.77
epoch = 349  |  train_loss = 0.147880  |  val_loss = 0.152714  |  training_for: 507.22
epoch = 350  |  train_loss = 0.147882  |  val_loss = 0.152620  |  training_for: 508.67
epoch = 351  |  train_loss = 0.147883  |  val_loss = 0.152890  |  training_for: 510.13
epoch = 352  |  train_loss = 0.147888  |  val_loss = 0.152786  |  training_for: 511.57
epoch = 353  |  train_loss = 0.147902  |  val_loss = 0.152557  |  training_for: 513.02
epoch = 354  |  train_loss = 0.147897  |  val_loss = 0.152371  |  training_for: 514.62
epoch = 355  |  train_loss = 0.147899  |  val_loss = 0.152096  |  training_for: 516.09
epoch = 356  |  train_loss = 0.147902  |  val_loss = 0.152453  |  training_for: 517.52
epoch = 357  |  train_loss = 0.147899  |  val_loss = 0.152356  |  training_for: 518.99
epoch = 358  |  train_loss = 0.147867  |  val_loss = 0.152158  |  training_for: 520.43
epoch = 359  |  train_loss = 0.147866  |  val_loss = 0.152351  |  training_for: 521.88
epoch = 360  |  train_loss = 0.147860  |  val_loss = 0.152671  |  training_for: 523.33
epoch = 361  |  train_loss = 0.147887  |  val_loss = 0.152740  |  training_for: 524.74
epoch = 362  |  train_loss = 0.147904  |  val_loss = 0.152252  |  training_for: 526.19
epoch = 363  |  train_loss = 0.147889  |  val_loss = 0.152378  |  training_for: 527.62
epoch = 364  |  train_loss = 0.147901  |  val_loss = 0.152855  |  training_for: 529.06
epoch = 365  |  train_loss = 0.147901  |  val_loss = 0.152689  |  training_for: 530.50
epoch = 366  |  train_loss = 0.147914  |  val_loss = 0.152316  |  training_for: 531.92
epoch = 367  |  train_loss = 0.147881  |  val_loss = 0.152630  |  training_for: 533.39
epoch = 368  |  train_loss = 0.147875  |  val_loss = 0.152888  |  training_for: 534.92
epoch = 369  |  train_loss = 0.147871  |  val_loss = 0.152431  |  training_for: 536.36
epoch = 370  |  train_loss = 0.147893  |  val_loss = 0.152458  |  training_for: 537.81
epoch = 371  |  train_loss = 0.147854  |  val_loss = 0.152422  |  training_for: 539.30
epoch = 372  |  train_loss = 0.147868  |  val_loss = 0.152428  |  training_for: 540.77
epoch = 373  |  train_loss = 0.147889  |  val_loss = 0.152930  |  training_for: 542.19
epoch = 374  |  train_loss = 0.147901  |  val_loss = 0.152559  |  training_for: 543.67
epoch = 375  |  train_loss = 0.147888  |  val_loss = 0.152917  |  training_for: 545.10
epoch = 376  |  train_loss = 0.147877  |  val_loss = 0.152946  |  training_for: 546.55
epoch = 377  |  train_loss = 0.147877  |  val_loss = 0.152751  |  training_for: 548.00
epoch = 378  |  train_loss = 0.147876  |  val_loss = 0.152672  |  training_for: 549.44
epoch = 379  |  train_loss = 0.147862  |  val_loss = 0.152445  |  training_for: 550.92
epoch = 380  |  train_loss = 0.147884  |  val_loss = 0.152827  |  training_for: 552.41
epoch = 381  |  train_loss = 0.147893  |  val_loss = 0.152105  |  training_for: 553.87
epoch = 382  |  train_loss = 0.147904  |  val_loss = 0.152865  |  training_for: 555.33
epoch = 383  |  train_loss = 0.147898  |  val_loss = 0.153783  |  training_for: 556.89
epoch = 384  |  train_loss = 0.147900  |  val_loss = 0.153147  |  training_for: 558.34
epoch = 385  |  train_loss = 0.147903  |  val_loss = 0.153060  |  training_for: 559.82
epoch = 386  |  train_loss = 0.147888  |  val_loss = 0.152457  |  training_for: 561.27
epoch = 387  |  train_loss = 0.147888  |  val_loss = 0.152712  |  training_for: 562.72
epoch = 388  |  train_loss = 0.147869  |  val_loss = 0.152514  |  training_for: 564.16
epoch = 389  |  train_loss = 0.147888  |  val_loss = 0.153037  |  training_for: 565.60
epoch = 390  |  train_loss = 0.147883  |  val_loss = 0.152415  |  training_for: 567.07
epoch = 391  |  train_loss = 0.147868  |  val_loss = 0.152609  |  training_for: 568.53
epoch = 392  |  train_loss = 0.147884  |  val_loss = 0.152895  |  training_for: 569.97
epoch = 393  |  train_loss = 0.147868  |  val_loss = 0.153074  |  training_for: 571.43
epoch = 394  |  train_loss = 0.147866  |  val_loss = 0.152527  |  training_for: 572.86
epoch = 395  |  train_loss = 0.147874  |  val_loss = 0.152650  |  training_for: 574.31
epoch = 396  |  train_loss = 0.147858  |  val_loss = 0.152590  |  training_for: 575.76
epoch = 397  |  train_loss = 0.147862  |  val_loss = 0.152897  |  training_for: 577.29
epoch = 398  |  train_loss = 0.147877  |  val_loss = 0.153104  |  training_for: 578.75
epoch = 399  |  train_loss = 0.147869  |  val_loss = 0.153210  |  training_for: 580.20
epoch = 400  |  train_loss = 0.147870  |  val_loss = 0.152649  |  training_for: 581.70
epoch = 401  |  train_loss = 0.147877  |  val_loss = 0.152635  |  training_for: 583.13
epoch = 402  |  train_loss = 0.147866  |  val_loss = 0.152777  |  training_for: 584.58
epoch = 403  |  train_loss = 0.147877  |  val_loss = 0.152765  |  training_for: 586.03
epoch = 404  |  train_loss = 0.147886  |  val_loss = 0.153144  |  training_for: 587.44
epoch = 405  |  train_loss = 0.147881  |  val_loss = 0.153107  |  training_for: 588.88
epoch = 406  |  train_loss = 0.147879  |  val_loss = 0.152251  |  training_for: 590.32
epoch = 407  |  train_loss = 0.147866  |  val_loss = 0.153067  |  training_for: 591.77
epoch = 408  |  train_loss = 0.147880  |  val_loss = 0.152728  |  training_for: 593.21
epoch = 409  |  train_loss = 0.147868  |  val_loss = 0.152951  |  training_for: 594.65
epoch = 410  |  train_loss = 0.147847  |  val_loss = 0.152852  |  training_for: 596.10
epoch = 411  |  train_loss = 0.147868  |  val_loss = 0.152229  |  training_for: 597.55
epoch = 412  |  train_loss = 0.147865  |  val_loss = 0.152059  |  training_for: 599.09
epoch = 413  |  train_loss = 0.147874  |  val_loss = 0.152180  |  training_for: 600.54
epoch = 414  |  train_loss = 0.147874  |  val_loss = 0.152000  |  training_for: 602.00
epoch = 415  |  train_loss = 0.147871  |  val_loss = 0.152062  |  training_for: 603.45
epoch = 416  |  train_loss = 0.147859  |  val_loss = 0.152398  |  training_for: 604.92
epoch = 417  |  train_loss = 0.147855  |  val_loss = 0.152456  |  training_for: 606.41
epoch = 418  |  train_loss = 0.147843  |  val_loss = 0.152792  |  training_for: 607.83
epoch = 419  |  train_loss = 0.147851  |  val_loss = 0.152767  |  training_for: 609.29
epoch = 420  |  train_loss = 0.147847  |  val_loss = 0.152304  |  training_for: 610.74
epoch = 421  |  train_loss = 0.147875  |  val_loss = 0.152052  |  training_for: 612.20
epoch = 422  |  train_loss = 0.147857  |  val_loss = 0.152288  |  training_for: 613.65
epoch = 423  |  train_loss = 0.147860  |  val_loss = 0.151899  |  training_for: 615.09
epoch = 424  |  train_loss = 0.147860  |  val_loss = 0.152452  |  training_for: 616.60
epoch = 425  |  train_loss = 0.147869  |  val_loss = 0.152774  |  training_for: 618.06
epoch = 426  |  train_loss = 0.147876  |  val_loss = 0.151958  |  training_for: 619.51
epoch = 427  |  train_loss = 0.147854  |  val_loss = 0.151814  |  training_for: 621.05
epoch = 428  |  train_loss = 0.147863  |  val_loss = 0.152623  |  training_for: 622.49
epoch = 429  |  train_loss = 0.147873  |  val_loss = 0.152963  |  training_for: 623.96
epoch = 430  |  train_loss = 0.147874  |  val_loss = 0.153158  |  training_for: 625.40
epoch = 431  |  train_loss = 0.147875  |  val_loss = 0.153042  |  training_for: 626.85
epoch = 432  |  train_loss = 0.147866  |  val_loss = 0.152782  |  training_for: 628.29
epoch = 433  |  train_loss = 0.147865  |  val_loss = 0.152526  |  training_for: 629.73
epoch = 434  |  train_loss = 0.147856  |  val_loss = 0.153007  |  training_for: 631.17
epoch = 435  |  train_loss = 0.147857  |  val_loss = 0.152627  |  training_for: 632.61
epoch = 436  |  train_loss = 0.147850  |  val_loss = 0.152743  |  training_for: 634.06
epoch = 437  |  train_loss = 0.147868  |  val_loss = 0.153229  |  training_for: 635.49
epoch = 438  |  train_loss = 0.147853  |  val_loss = 0.152286  |  training_for: 636.94
epoch = 439  |  train_loss = 0.147864  |  val_loss = 0.152087  |  training_for: 638.39
epoch = 440  |  train_loss = 0.147860  |  val_loss = 0.152584  |  training_for: 639.83
epoch = 441  |  train_loss = 0.147842  |  val_loss = 0.152410  |  training_for: 641.37
epoch = 442  |  train_loss = 0.147844  |  val_loss = 0.151908  |  training_for: 642.80
epoch = 443  |  train_loss = 0.147838  |  val_loss = 0.152110  |  training_for: 644.31
epoch = 444  |  train_loss = 0.147848  |  val_loss = 0.152787  |  training_for: 645.76
epoch = 445  |  train_loss = 0.147874  |  val_loss = 0.153207  |  training_for: 647.21
epoch = 446  |  train_loss = 0.147855  |  val_loss = 0.152469  |  training_for: 648.65
epoch = 447  |  train_loss = 0.147865  |  val_loss = 0.152256  |  training_for: 650.11
epoch = 448  |  train_loss = 0.147854  |  val_loss = 0.152359  |  training_for: 651.57
epoch = 449  |  train_loss = 0.147851  |  val_loss = 0.152513  |  training_for: 653.01
epoch = 450  |  train_loss = 0.147843  |  val_loss = 0.152445  |  training_for: 654.48
epoch = 451  |  train_loss = 0.147852  |  val_loss = 0.152985  |  training_for: 655.91
epoch = 452  |  train_loss = 0.147859  |  val_loss = 0.152891  |  training_for: 657.37
epoch = 453  |  train_loss = 0.147874  |  val_loss = 0.152392  |  training_for: 658.81
epoch = 454  |  train_loss = 0.147851  |  val_loss = 0.152065  |  training_for: 660.24
epoch = 455  |  train_loss = 0.147852  |  val_loss = 0.152447  |  training_for: 661.69
epoch = 456  |  train_loss = 0.147852  |  val_loss = 0.152172  |  training_for: 663.21
epoch = 457  |  train_loss = 0.147856  |  val_loss = 0.152099  |  training_for: 664.67
epoch = 458  |  train_loss = 0.147850  |  val_loss = 0.152463  |  training_for: 666.15
epoch = 459  |  train_loss = 0.147853  |  val_loss = 0.152361  |  training_for: 667.61
epoch = 460  |  train_loss = 0.147832  |  val_loss = 0.152785  |  training_for: 669.05
epoch = 461  |  train_loss = 0.147838  |  val_loss = 0.152202  |  training_for: 670.47
epoch = 462  |  train_loss = 0.147858  |  val_loss = 0.152233  |  training_for: 671.92
epoch = 463  |  train_loss = 0.147865  |  val_loss = 0.152245  |  training_for: 673.37
epoch = 464  |  train_loss = 0.147827  |  val_loss = 0.152283  |  training_for: 674.81
epoch = 465  |  train_loss = 0.147854  |  val_loss = 0.152460  |  training_for: 676.26
epoch = 466  |  train_loss = 0.147857  |  val_loss = 0.152442  |  training_for: 677.74
epoch = 467  |  train_loss = 0.147864  |  val_loss = 0.152211  |  training_for: 679.23
epoch = 468  |  train_loss = 0.147866  |  val_loss = 0.152558  |  training_for: 680.68
epoch = 469  |  train_loss = 0.147846  |  val_loss = 0.152506  |  training_for: 682.13
epoch = 470  |  train_loss = 0.147850  |  val_loss = 0.152217  |  training_for: 683.58
epoch = 471  |  train_loss = 0.147849  |  val_loss = 0.153090  |  training_for: 685.14
epoch = 472  |  train_loss = 0.147843  |  val_loss = 0.152516  |  training_for: 686.60
epoch = 473  |  train_loss = 0.147849  |  val_loss = 0.152609  |  training_for: 688.04
epoch = 474  |  train_loss = 0.147853  |  val_loss = 0.152914  |  training_for: 689.50
epoch = 475  |  train_loss = 0.147852  |  val_loss = 0.152450  |  training_for: 690.97
epoch = 476  |  train_loss = 0.147841  |  val_loss = 0.152119  |  training_for: 692.42
epoch = 477  |  train_loss = 0.147845  |  val_loss = 0.151865  |  training_for: 693.87
epoch = 478  |  train_loss = 0.147847  |  val_loss = 0.152257  |  training_for: 695.32
epoch = 479  |  train_loss = 0.147846  |  val_loss = 0.152567  |  training_for: 696.80
epoch = 480  |  train_loss = 0.147844  |  val_loss = 0.151997  |  training_for: 698.25
epoch = 481  |  train_loss = 0.147847  |  val_loss = 0.151912  |  training_for: 699.72
epoch = 482  |  train_loss = 0.147846  |  val_loss = 0.152521  |  training_for: 701.17
epoch = 483  |  train_loss = 0.147843  |  val_loss = 0.152187  |  training_for: 702.63
epoch = 484  |  train_loss = 0.147836  |  val_loss = 0.152193  |  training_for: 704.09
epoch = 485  |  train_loss = 0.147855  |  val_loss = 0.151970  |  training_for: 705.54
epoch = 486  |  train_loss = 0.147851  |  val_loss = 0.152242  |  training_for: 707.11
epoch = 487  |  train_loss = 0.147845  |  val_loss = 0.152185  |  training_for: 708.57
epoch = 488  |  train_loss = 0.147835  |  val_loss = 0.152371  |  training_for: 710.04
epoch = 489  |  train_loss = 0.147838  |  val_loss = 0.152315  |  training_for: 711.49
epoch = 490  |  train_loss = 0.147831  |  val_loss = 0.151745  |  training_for: 712.93
epoch = 491  |  train_loss = 0.147828  |  val_loss = 0.151872  |  training_for: 714.44
epoch = 492  |  train_loss = 0.147844  |  val_loss = 0.152246  |  training_for: 715.90
epoch = 493  |  train_loss = 0.147822  |  val_loss = 0.151968  |  training_for: 717.36
epoch = 494  |  train_loss = 0.147833  |  val_loss = 0.152178  |  training_for: 718.81
epoch = 495  |  train_loss = 0.147823  |  val_loss = 0.152221  |  training_for: 720.27
epoch = 496  |  train_loss = 0.147842  |  val_loss = 0.152308  |  training_for: 721.76
epoch = 497  |  train_loss = 0.147853  |  val_loss = 0.152483  |  training_for: 723.21
epoch = 498  |  train_loss = 0.147869  |  val_loss = 0.152254  |  training_for: 724.70
epoch = 499  |  train_loss = 0.147845  |  val_loss = 0.151959  |  training_for: 726.18
epoch = 500  |  train_loss = 0.147831  |  val_loss = 0.152234  |  training_for: 727.64
epoch = 501  |  train_loss = 0.147843  |  val_loss = 0.151878  |  training_for: 729.20
epoch = 502  |  train_loss = 0.147837  |  val_loss = 0.152006  |  training_for: 730.70
epoch = 503  |  train_loss = 0.147840  |  val_loss = 0.152269  |  training_for: 732.15
epoch = 504  |  train_loss = 0.147813  |  val_loss = 0.152621  |  training_for: 733.59
epoch = 505  |  train_loss = 0.147836  |  val_loss = 0.152732  |  training_for: 735.06
epoch = 506  |  train_loss = 0.147854  |  val_loss = 0.152321  |  training_for: 736.53
epoch = 507  |  train_loss = 0.147844  |  val_loss = 0.151653  |  training_for: 737.98
epoch = 508  |  train_loss = 0.147831  |  val_loss = 0.152411  |  training_for: 739.42
epoch = 509  |  train_loss = 0.147840  |  val_loss = 0.152287  |  training_for: 740.86
epoch = 510  |  train_loss = 0.147855  |  val_loss = 0.152146  |  training_for: 742.31
epoch = 511  |  train_loss = 0.147824  |  val_loss = 0.152337  |  training_for: 743.75
epoch = 512  |  train_loss = 0.147834  |  val_loss = 0.152673  |  training_for: 745.20
epoch = 513  |  train_loss = 0.147822  |  val_loss = 0.152405  |  training_for: 746.64
epoch = 514  |  train_loss = 0.147828  |  val_loss = 0.152244  |  training_for: 748.06
epoch = 515  |  train_loss = 0.147820  |  val_loss = 0.152472  |  training_for: 749.54
epoch = 516  |  train_loss = 0.147823  |  val_loss = 0.152294  |  training_for: 751.09
epoch = 517  |  train_loss = 0.147825  |  val_loss = 0.152634  |  training_for: 752.56
epoch = 518  |  train_loss = 0.147841  |  val_loss = 0.152094  |  training_for: 754.01
epoch = 519  |  train_loss = 0.147817  |  val_loss = 0.152184  |  training_for: 755.47
epoch = 520  |  train_loss = 0.147820  |  val_loss = 0.152144  |  training_for: 756.91
epoch = 521  |  train_loss = 0.147820  |  val_loss = 0.152320  |  training_for: 758.39
epoch = 522  |  train_loss = 0.147820  |  val_loss = 0.152388  |  training_for: 759.85
epoch = 523  |  train_loss = 0.147823  |  val_loss = 0.151494  |  training_for: 761.31
epoch = 524  |  train_loss = 0.147844  |  val_loss = 0.151658  |  training_for: 762.77
epoch = 525  |  train_loss = 0.147824  |  val_loss = 0.151746  |  training_for: 764.22
epoch = 526  |  train_loss = 0.147832  |  val_loss = 0.151476  |  training_for: 765.67
epoch = 527  |  train_loss = 0.147827  |  val_loss = 0.151629  |  training_for: 767.17
epoch = 528  |  train_loss = 0.147818  |  val_loss = 0.151734  |  training_for: 768.58
epoch = 529  |  train_loss = 0.147860  |  val_loss = 0.151928  |  training_for: 770.03
epoch = 530  |  train_loss = 0.147822  |  val_loss = 0.152009  |  training_for: 771.48
epoch = 531  |  train_loss = 0.147802  |  val_loss = 0.151869  |  training_for: 773.06
epoch = 532  |  train_loss = 0.147819  |  val_loss = 0.151774  |  training_for: 774.55
epoch = 533  |  train_loss = 0.147832  |  val_loss = 0.151635  |  training_for: 776.00
epoch = 534  |  train_loss = 0.147828  |  val_loss = 0.152143  |  training_for: 777.46
epoch = 535  |  train_loss = 0.147824  |  val_loss = 0.151685  |  training_for: 778.90
epoch = 536  |  train_loss = 0.147831  |  val_loss = 0.151999  |  training_for: 780.37
epoch = 537  |  train_loss = 0.147827  |  val_loss = 0.151617  |  training_for: 781.81
epoch = 538  |  train_loss = 0.147814  |  val_loss = 0.152024  |  training_for: 783.29
epoch = 539  |  train_loss = 0.147804  |  val_loss = 0.152072  |  training_for: 784.75
epoch = 540  |  train_loss = 0.147834  |  val_loss = 0.152059  |  training_for: 786.21
epoch = 541  |  train_loss = 0.147837  |  val_loss = 0.152034  |  training_for: 787.68
epoch = 542  |  train_loss = 0.147824  |  val_loss = 0.151859  |  training_for: 789.14
epoch = 543  |  train_loss = 0.147810  |  val_loss = 0.151774  |  training_for: 790.61
epoch = 544  |  train_loss = 0.147812  |  val_loss = 0.151715  |  training_for: 792.08
epoch = 545  |  train_loss = 0.147837  |  val_loss = 0.151757  |  training_for: 793.52
epoch = 546  |  train_loss = 0.147828  |  val_loss = 0.151892  |  training_for: 795.09
epoch = 547  |  train_loss = 0.147816  |  val_loss = 0.151944  |  training_for: 796.54
epoch = 548  |  train_loss = 0.147810  |  val_loss = 0.152027  |  training_for: 798.00
epoch = 549  |  train_loss = 0.147807  |  val_loss = 0.151825  |  training_for: 799.45
epoch = 550  |  train_loss = 0.147818  |  val_loss = 0.151553  |  training_for: 800.90
epoch = 551  |  train_loss = 0.147814  |  val_loss = 0.151319  |  training_for: 802.37
epoch = 552  |  train_loss = 0.147816  |  val_loss = 0.152023  |  training_for: 803.82
epoch = 553  |  train_loss = 0.147817  |  val_loss = 0.152120  |  training_for: 805.28
epoch = 554  |  train_loss = 0.147809  |  val_loss = 0.151523  |  training_for: 806.72
epoch = 555  |  train_loss = 0.147825  |  val_loss = 0.151676  |  training_for: 808.19
epoch = 556  |  train_loss = 0.147838  |  val_loss = 0.151045  |  training_for: 809.65
epoch = 557  |  train_loss = 0.147854  |  val_loss = 0.150995  |  training_for: 811.11
epoch = 558  |  train_loss = 0.147844  |  val_loss = 0.152104  |  training_for: 812.58
epoch = 559  |  train_loss = 0.147839  |  val_loss = 0.152451  |  training_for: 814.02
epoch = 560  |  train_loss = 0.147813  |  val_loss = 0.151688  |  training_for: 815.47
epoch = 561  |  train_loss = 0.147819  |  val_loss = 0.152160  |  training_for: 817.02
epoch = 562  |  train_loss = 0.147823  |  val_loss = 0.151839  |  training_for: 818.47
epoch = 563  |  train_loss = 0.147814  |  val_loss = 0.151384  |  training_for: 819.94
epoch = 564  |  train_loss = 0.147807  |  val_loss = 0.151583  |  training_for: 821.41
epoch = 565  |  train_loss = 0.147808  |  val_loss = 0.151708  |  training_for: 822.87
epoch = 566  |  train_loss = 0.147805  |  val_loss = 0.152028  |  training_for: 824.32
epoch = 567  |  train_loss = 0.147807  |  val_loss = 0.151281  |  training_for: 825.79
epoch = 568  |  train_loss = 0.147798  |  val_loss = 0.151389  |  training_for: 827.25
epoch = 569  |  train_loss = 0.147815  |  val_loss = 0.152167  |  training_for: 828.71
epoch = 570  |  train_loss = 0.147816  |  val_loss = 0.151551  |  training_for: 830.16
epoch = 571  |  train_loss = 0.147824  |  val_loss = 0.151589  |  training_for: 831.63
epoch = 572  |  train_loss = 0.147811  |  val_loss = 0.151730  |  training_for: 833.08
epoch = 573  |  train_loss = 0.147809  |  val_loss = 0.151287  |  training_for: 834.53
epoch = 574  |  train_loss = 0.147820  |  val_loss = 0.151441  |  training_for: 836.02
epoch = 575  |  train_loss = 0.147817  |  val_loss = 0.151334  |  training_for: 837.48
epoch = 576  |  train_loss = 0.147806  |  val_loss = 0.151338  |  training_for: 839.06
epoch = 577  |  train_loss = 0.147814  |  val_loss = 0.151527  |  training_for: 840.51
epoch = 578  |  train_loss = 0.147808  |  val_loss = 0.151307  |  training_for: 841.96
epoch = 579  |  train_loss = 0.147817  |  val_loss = 0.151411  |  training_for: 843.40
epoch = 580  |  train_loss = 0.147810  |  val_loss = 0.151978  |  training_for: 844.85
epoch = 581  |  train_loss = 0.147815  |  val_loss = 0.151998  |  training_for: 846.29
epoch = 582  |  train_loss = 0.147819  |  val_loss = 0.151490  |  training_for: 847.76
epoch = 583  |  train_loss = 0.147820  |  val_loss = 0.151606  |  training_for: 849.19
epoch = 584  |  train_loss = 0.147817  |  val_loss = 0.150912  |  training_for: 850.66
epoch = 585  |  train_loss = 0.147826  |  val_loss = 0.151188  |  training_for: 852.09
epoch = 586  |  train_loss = 0.147836  |  val_loss = 0.151178  |  training_for: 853.53
epoch = 587  |  train_loss = 0.147824  |  val_loss = 0.151639  |  training_for: 855.00
epoch = 588  |  train_loss = 0.147833  |  val_loss = 0.152031  |  training_for: 856.46
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 114, in main
    train(model = model,
  File "/home/jwilkie/code_base/packages/model_training/training_loops.py", line 118, in train
    loss = loss_calc(model, batch)  #compute training loss
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/saint/composite_loss.py", line 46, in calc_loss
    z_aug = model.feed_aug(x)
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/saint/saint.py", line 141, in feed_aug
    return self.encoder(self.latent_aug(self.embedding_layer(self.feature_aug(x))))
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/encoders.py", line 57, in forward
    if self.norm_output: x = self.norm(x) # normalise output if required
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/normalisation.py", line 76, in forward
    return self.scale * x_normed
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.69 GiB total capacity; 21.90 GiB already allocated; 3.81 MiB free; 23.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.