epoch = 0  |  train_loss = 0.101911  |  val_loss = 0.095049  |  training_for: 1.20
epoch = 1  |  train_loss = 0.101906  |  val_loss = 0.095026  |  training_for: 2.05
epoch = 2  |  train_loss = 0.101863  |  val_loss = 0.094998  |  training_for: 2.89
epoch = 3  |  train_loss = 0.101801  |  val_loss = 0.094957  |  training_for: 3.74
epoch = 4  |  train_loss = 0.101686  |  val_loss = 0.094901  |  training_for: 4.59
epoch = 5  |  train_loss = 0.101585  |  val_loss = 0.094828  |  training_for: 5.42
epoch = 6  |  train_loss = 0.101451  |  val_loss = 0.094748  |  training_for: 6.28
epoch = 7  |  train_loss = 0.101377  |  val_loss = 0.094654  |  training_for: 7.14
epoch = 8  |  train_loss = 0.101115  |  val_loss = 0.094551  |  training_for: 8.10
epoch = 9  |  train_loss = 0.100990  |  val_loss = 0.094440  |  training_for: 8.93
epoch = 10  |  train_loss = 0.100750  |  val_loss = 0.094317  |  training_for: 9.77
epoch = 11  |  train_loss = 0.100605  |  val_loss = 0.094192  |  training_for: 10.64
epoch = 12  |  train_loss = 0.100404  |  val_loss = 0.094066  |  training_for: 11.48
epoch = 13  |  train_loss = 0.100167  |  val_loss = 0.093955  |  training_for: 12.33
epoch = 14  |  train_loss = 0.099923  |  val_loss = 0.093848  |  training_for: 13.19
epoch = 15  |  train_loss = 0.099786  |  val_loss = 0.093750  |  training_for: 14.13
epoch = 16  |  train_loss = 0.099547  |  val_loss = 0.093639  |  training_for: 14.99
epoch = 17  |  train_loss = 0.099344  |  val_loss = 0.093533  |  training_for: 15.83
epoch = 18  |  train_loss = 0.099145  |  val_loss = 0.093427  |  training_for: 16.67
epoch = 19  |  train_loss = 0.098928  |  val_loss = 0.093340  |  training_for: 17.52
epoch = 20  |  train_loss = 0.098753  |  val_loss = 0.093266  |  training_for: 18.36
epoch = 21  |  train_loss = 0.098600  |  val_loss = 0.093181  |  training_for: 19.20
epoch = 22  |  train_loss = 0.098395  |  val_loss = 0.093111  |  training_for: 20.05
epoch = 23  |  train_loss = 0.098218  |  val_loss = 0.093073  |  training_for: 20.88
epoch = 24  |  train_loss = 0.098070  |  val_loss = 0.093064  |  training_for: 21.72
epoch = 25  |  train_loss = 0.097863  |  val_loss = 0.093075  |  training_for: 22.68
epoch = 26  |  train_loss = 0.097631  |  val_loss = 0.093027  |  training_for: 23.52
epoch = 27  |  train_loss = 0.097493  |  val_loss = 0.092941  |  training_for: 24.35
epoch = 28  |  train_loss = 0.097326  |  val_loss = 0.092861  |  training_for: 25.24
epoch = 29  |  train_loss = 0.097082  |  val_loss = 0.092832  |  training_for: 26.09
epoch = 30  |  train_loss = 0.096961  |  val_loss = 0.092858  |  training_for: 26.94
epoch = 31  |  train_loss = 0.096781  |  val_loss = 0.092827  |  training_for: 27.82
epoch = 32  |  train_loss = 0.096567  |  val_loss = 0.092708  |  training_for: 28.67
epoch = 33  |  train_loss = 0.096451  |  val_loss = 0.092636  |  training_for: 29.51
epoch = 34  |  train_loss = 0.096306  |  val_loss = 0.092586  |  training_for: 30.37
epoch = 35  |  train_loss = 0.096103  |  val_loss = 0.092596  |  training_for: 31.21
epoch = 36  |  train_loss = 0.095954  |  val_loss = 0.092580  |  training_for: 32.15
epoch = 37  |  train_loss = 0.095803  |  val_loss = 0.092453  |  training_for: 32.99
epoch = 38  |  train_loss = 0.095638  |  val_loss = 0.092330  |  training_for: 33.82
epoch = 39  |  train_loss = 0.095506  |  val_loss = 0.092200  |  training_for: 34.67
epoch = 40  |  train_loss = 0.095408  |  val_loss = 0.092022  |  training_for: 35.51
epoch = 41  |  train_loss = 0.095256  |  val_loss = 0.091869  |  training_for: 36.35
epoch = 42  |  train_loss = 0.095123  |  val_loss = 0.091790  |  training_for: 37.19
epoch = 43  |  train_loss = 0.094973  |  val_loss = 0.091669  |  training_for: 38.14
epoch = 44  |  train_loss = 0.094785  |  val_loss = 0.091572  |  training_for: 38.97
epoch = 45  |  train_loss = 0.094629  |  val_loss = 0.091633  |  training_for: 39.82
epoch = 46  |  train_loss = 0.094477  |  val_loss = 0.091729  |  training_for: 40.69
epoch = 47  |  train_loss = 0.094334  |  val_loss = 0.092027  |  training_for: 41.53
epoch = 48  |  train_loss = 0.094154  |  val_loss = 0.092340  |  training_for: 42.42
epoch = 49  |  train_loss = 0.093949  |  val_loss = 0.092701  |  training_for: 43.31
epoch = 50  |  train_loss = 0.093783  |  val_loss = 0.092952  |  training_for: 44.21
epoch = 51  |  train_loss = 0.093625  |  val_loss = 0.093192  |  training_for: 45.05
epoch = 52  |  train_loss = 0.093469  |  val_loss = 0.093400  |  training_for: 45.92
epoch = 53  |  train_loss = 0.093282  |  val_loss = 0.093558  |  training_for: 46.76
epoch = 54  |  train_loss = 0.093149  |  val_loss = 0.093734  |  training_for: 47.72
epoch = 55  |  train_loss = 0.093007  |  val_loss = 0.093771  |  training_for: 48.56
epoch = 56  |  train_loss = 0.092886  |  val_loss = 0.093827  |  training_for: 49.40
epoch = 57  |  train_loss = 0.092757  |  val_loss = 0.093753  |  training_for: 50.26
epoch = 58  |  train_loss = 0.092660  |  val_loss = 0.093850  |  training_for: 51.10
epoch = 59  |  train_loss = 0.092558  |  val_loss = 0.093533  |  training_for: 51.95
epoch = 60  |  train_loss = 0.092484  |  val_loss = 0.093322  |  training_for: 52.82
epoch = 61  |  train_loss = 0.092381  |  val_loss = 0.092990  |  training_for: 53.76
epoch = 62  |  train_loss = 0.092323  |  val_loss = 0.092830  |  training_for: 54.60
epoch = 63  |  train_loss = 0.092244  |  val_loss = 0.092728  |  training_for: 55.45
epoch = 64  |  train_loss = 0.092187  |  val_loss = 0.092472  |  training_for: 56.29
epoch = 65  |  train_loss = 0.092123  |  val_loss = 0.092380  |  training_for: 57.13
epoch = 66  |  train_loss = 0.092049  |  val_loss = 0.092534  |  training_for: 57.98
epoch = 67  |  train_loss = 0.092019  |  val_loss = 0.092274  |  training_for: 58.81
epoch = 68  |  train_loss = 0.091953  |  val_loss = 0.092311  |  training_for: 59.66
epoch = 69  |  train_loss = 0.091893  |  val_loss = 0.092521  |  training_for: 60.51
epoch = 70  |  train_loss = 0.091861  |  val_loss = 0.092505  |  training_for: 61.38
epoch = 71  |  train_loss = 0.091804  |  val_loss = 0.092508  |  training_for: 62.23
epoch = 72  |  train_loss = 0.091745  |  val_loss = 0.092617  |  training_for: 63.21
epoch = 73  |  train_loss = 0.091701  |  val_loss = 0.092593  |  training_for: 64.07
epoch = 74  |  train_loss = 0.091657  |  val_loss = 0.092499  |  training_for: 64.91
epoch = 75  |  train_loss = 0.091621  |  val_loss = 0.092360  |  training_for: 65.80
epoch = 76  |  train_loss = 0.091578  |  val_loss = 0.091803  |  training_for: 66.64
epoch = 77  |  train_loss = 0.091544  |  val_loss = 0.091912  |  training_for: 67.50
epoch = 78  |  train_loss = 0.091494  |  val_loss = 0.091455  |  training_for: 68.37
epoch = 79  |  train_loss = 0.091456  |  val_loss = 0.090956  |  training_for: 69.31
epoch = 80  |  train_loss = 0.091422  |  val_loss = 0.090872  |  training_for: 70.16
epoch = 81  |  train_loss = 0.091383  |  val_loss = 0.090113  |  training_for: 71.01
epoch = 82  |  train_loss = 0.091351  |  val_loss = 0.089769  |  training_for: 71.85
epoch = 83  |  train_loss = 0.091320  |  val_loss = 0.089589  |  training_for: 72.69
epoch = 84  |  train_loss = 0.091272  |  val_loss = 0.089365  |  training_for: 73.55
epoch = 85  |  train_loss = 0.091249  |  val_loss = 0.089071  |  training_for: 74.40
epoch = 86  |  train_loss = 0.091236  |  val_loss = 0.089277  |  training_for: 75.24
epoch = 87  |  train_loss = 0.091206  |  val_loss = 0.088755  |  training_for: 76.08
epoch = 88  |  train_loss = 0.091170  |  val_loss = 0.089079  |  training_for: 76.92
epoch = 89  |  train_loss = 0.091145  |  val_loss = 0.089585  |  training_for: 77.76
epoch = 90  |  train_loss = 0.091124  |  val_loss = 0.089190  |  training_for: 78.75
epoch = 91  |  train_loss = 0.091104  |  val_loss = 0.089556  |  training_for: 79.59
epoch = 92  |  train_loss = 0.091077  |  val_loss = 0.089531  |  training_for: 80.46
epoch = 93  |  train_loss = 0.091054  |  val_loss = 0.089664  |  training_for: 81.34
epoch = 94  |  train_loss = 0.091035  |  val_loss = 0.089813  |  training_for: 82.19
epoch = 95  |  train_loss = 0.091015  |  val_loss = 0.090012  |  training_for: 83.04
epoch = 96  |  train_loss = 0.091005  |  val_loss = 0.090077  |  training_for: 83.88
epoch = 97  |  train_loss = 0.090994  |  val_loss = 0.090102  |  training_for: 84.82
epoch = 98  |  train_loss = 0.090982  |  val_loss = 0.090327  |  training_for: 85.68
epoch = 99  |  train_loss = 0.090955  |  val_loss = 0.090200  |  training_for: 86.51
epoch = 100  |  train_loss = 0.090934  |  val_loss = 0.090348  |  training_for: 87.36
epoch = 101  |  train_loss = 0.090918  |  val_loss = 0.090153  |  training_for: 88.21
epoch = 102  |  train_loss = 0.090910  |  val_loss = 0.090308  |  training_for: 89.07
epoch = 103  |  train_loss = 0.090893  |  val_loss = 0.090310  |  training_for: 89.96
epoch = 104  |  train_loss = 0.090883  |  val_loss = 0.090455  |  training_for: 90.82
epoch = 105  |  train_loss = 0.090882  |  val_loss = 0.090263  |  training_for: 91.69
epoch = 106  |  train_loss = 0.090879  |  val_loss = 0.090260  |  training_for: 92.55
Traceback (most recent call last):
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 132, in <module>
    main()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 118, in main
    train(model = model,
  File "/home/jwilkie/code_base/packages/model_training/training_loops.py", line 120, in train
    for batch_num, batch in enumerate(train_dl):
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 678, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
KeyboardInterrupt