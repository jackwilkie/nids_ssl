epoch = 0  |  train_loss = 0.165517  |  val_loss = 0.152572  |  training_for: 1.78
epoch = 1  |  train_loss = 0.151432  |  val_loss = 0.149864  |  training_for: 3.21
epoch = 2  |  train_loss = 0.149123  |  val_loss = 0.149869  |  training_for: 4.65
epoch = 3  |  train_loss = 0.148392  |  val_loss = 0.150918  |  training_for: 6.10
epoch = 4  |  train_loss = 0.148140  |  val_loss = 0.150018  |  training_for: 7.55
epoch = 5  |  train_loss = 0.147974  |  val_loss = 0.150495  |  training_for: 8.99
epoch = 6  |  train_loss = 0.147887  |  val_loss = 0.150610  |  training_for: 10.44
epoch = 7  |  train_loss = 0.147799  |  val_loss = 0.150568  |  training_for: 11.88
epoch = 8  |  train_loss = 0.147763  |  val_loss = 0.150948  |  training_for: 13.31
epoch = 9  |  train_loss = 0.147703  |  val_loss = 0.150339  |  training_for: 14.75
epoch = 10  |  train_loss = 0.147631  |  val_loss = 0.150765  |  training_for: 16.29
epoch = 11  |  train_loss = 0.147564  |  val_loss = 0.151467  |  training_for: 17.74
epoch = 12  |  train_loss = 0.147526  |  val_loss = 0.151699  |  training_for: 19.18
epoch = 13  |  train_loss = 0.147549  |  val_loss = 0.152406  |  training_for: 20.62
epoch = 14  |  train_loss = 0.147499  |  val_loss = 0.151860  |  training_for: 22.06
epoch = 15  |  train_loss = 0.147544  |  val_loss = 0.152206  |  training_for: 23.56
epoch = 16  |  train_loss = 0.147537  |  val_loss = 0.152175  |  training_for: 25.00
epoch = 17  |  train_loss = 0.147507  |  val_loss = 0.152028  |  training_for: 26.44
epoch = 18  |  train_loss = 0.147459  |  val_loss = 0.151506  |  training_for: 27.87
epoch = 19  |  train_loss = 0.147394  |  val_loss = 0.151379  |  training_for: 29.31
epoch = 20  |  train_loss = 0.147430  |  val_loss = 0.151860  |  training_for: 30.77
epoch = 21  |  train_loss = 0.147447  |  val_loss = 0.152193  |  training_for: 32.23
epoch = 22  |  train_loss = 0.147447  |  val_loss = 0.152032  |  training_for: 33.72
epoch = 23  |  train_loss = 0.147406  |  val_loss = 0.152537  |  training_for: 35.16
epoch = 24  |  train_loss = 0.147371  |  val_loss = 0.151499  |  training_for: 36.70
epoch = 25  |  train_loss = 0.147403  |  val_loss = 0.151861  |  training_for: 38.14
epoch = 26  |  train_loss = 0.147351  |  val_loss = 0.152322  |  training_for: 39.57
epoch = 27  |  train_loss = 0.147381  |  val_loss = 0.151920  |  training_for: 41.01
epoch = 28  |  train_loss = 0.147415  |  val_loss = 0.151741  |  training_for: 42.45
epoch = 29  |  train_loss = 0.147394  |  val_loss = 0.151813  |  training_for: 43.90
epoch = 30  |  train_loss = 0.147395  |  val_loss = 0.151597  |  training_for: 45.36
epoch = 31  |  train_loss = 0.147362  |  val_loss = 0.152056  |  training_for: 46.81
epoch = 32  |  train_loss = 0.147390  |  val_loss = 0.152006  |  training_for: 48.26
epoch = 33  |  train_loss = 0.147291  |  val_loss = 0.151914  |  training_for: 49.77
epoch = 34  |  train_loss = 0.147302  |  val_loss = 0.151518  |  training_for: 51.22
epoch = 35  |  train_loss = 0.147317  |  val_loss = 0.152089  |  training_for: 52.69
epoch = 36  |  train_loss = 0.147331  |  val_loss = 0.152597  |  training_for: 54.14
epoch = 37  |  train_loss = 0.147357  |  val_loss = 0.152534  |  training_for: 55.69
epoch = 38  |  train_loss = 0.147343  |  val_loss = 0.152109  |  training_for: 57.14
epoch = 39  |  train_loss = 0.147365  |  val_loss = 0.152088  |  training_for: 58.59
epoch = 40  |  train_loss = 0.147340  |  val_loss = 0.152667  |  training_for: 60.05
epoch = 41  |  train_loss = 0.147328  |  val_loss = 0.151655  |  training_for: 61.51
epoch = 42  |  train_loss = 0.147319  |  val_loss = 0.152714  |  training_for: 62.96
epoch = 43  |  train_loss = 0.147355  |  val_loss = 0.153108  |  training_for: 64.44
epoch = 44  |  train_loss = 0.147311  |  val_loss = 0.152261  |  training_for: 65.90
epoch = 45  |  train_loss = 0.147312  |  val_loss = 0.152613  |  training_for: 67.35
epoch = 46  |  train_loss = 0.147279  |  val_loss = 0.152496  |  training_for: 68.80
epoch = 47  |  train_loss = 0.147261  |  val_loss = 0.152816  |  training_for: 70.25
epoch = 48  |  train_loss = 0.147298  |  val_loss = 0.153651  |  training_for: 71.70
epoch = 49  |  train_loss = 0.147335  |  val_loss = 0.152957  |  training_for: 73.15
epoch = 50  |  train_loss = 0.147279  |  val_loss = 0.152097  |  training_for: 74.70
epoch = 51  |  train_loss = 0.147292  |  val_loss = 0.151771  |  training_for: 76.16
epoch = 52  |  train_loss = 0.147262  |  val_loss = 0.152444  |  training_for: 77.61
epoch = 53  |  train_loss = 0.147264  |  val_loss = 0.152752  |  training_for: 79.06
epoch = 54  |  train_loss = 0.147262  |  val_loss = 0.151969  |  training_for: 80.51
epoch = 55  |  train_loss = 0.147268  |  val_loss = 0.153071  |  training_for: 81.97
epoch = 56  |  train_loss = 0.147239  |  val_loss = 0.151762  |  training_for: 83.42
epoch = 57  |  train_loss = 0.147279  |  val_loss = 0.152167  |  training_for: 84.87
epoch = 58  |  train_loss = 0.147286  |  val_loss = 0.152815  |  training_for: 86.33
epoch = 59  |  train_loss = 0.147285  |  val_loss = 0.152626  |  training_for: 87.78
epoch = 60  |  train_loss = 0.147268  |  val_loss = 0.153197  |  training_for: 89.23
epoch = 61  |  train_loss = 0.147260  |  val_loss = 0.152979  |  training_for: 90.69
epoch = 62  |  train_loss = 0.147265  |  val_loss = 0.153071  |  training_for: 92.14
epoch = 63  |  train_loss = 0.147256  |  val_loss = 0.152250  |  training_for: 93.60
epoch = 64  |  train_loss = 0.147242  |  val_loss = 0.152614  |  training_for: 95.17
epoch = 65  |  train_loss = 0.147257  |  val_loss = 0.152429  |  training_for: 96.63
epoch = 66  |  train_loss = 0.147245  |  val_loss = 0.152626  |  training_for: 98.09
epoch = 67  |  train_loss = 0.147224  |  val_loss = 0.152952  |  training_for: 99.54
epoch = 68  |  train_loss = 0.147251  |  val_loss = 0.152513  |  training_for: 101.01
epoch = 69  |  train_loss = 0.147235  |  val_loss = 0.152552  |  training_for: 102.46
epoch = 70  |  train_loss = 0.147252  |  val_loss = 0.152834  |  training_for: 103.92
epoch = 71  |  train_loss = 0.147228  |  val_loss = 0.153103  |  training_for: 105.40
epoch = 72  |  train_loss = 0.147197  |  val_loss = 0.152824  |  training_for: 106.85
epoch = 73  |  train_loss = 0.147221  |  val_loss = 0.153090  |  training_for: 108.31
epoch = 74  |  train_loss = 0.147248  |  val_loss = 0.153029  |  training_for: 109.77
epoch = 75  |  train_loss = 0.147223  |  val_loss = 0.152745  |  training_for: 111.25
epoch = 76  |  train_loss = 0.147207  |  val_loss = 0.152969  |  training_for: 112.70
epoch = 77  |  train_loss = 0.147232  |  val_loss = 0.152802  |  training_for: 114.26
epoch = 78  |  train_loss = 0.147224  |  val_loss = 0.152370  |  training_for: 115.71
epoch = 79  |  train_loss = 0.147219  |  val_loss = 0.152848  |  training_for: 117.17
epoch = 80  |  train_loss = 0.147206  |  val_loss = 0.152621  |  training_for: 118.62
epoch = 81  |  train_loss = 0.147220  |  val_loss = 0.153567  |  training_for: 120.08
epoch = 82  |  train_loss = 0.147200  |  val_loss = 0.152920  |  training_for: 121.53
epoch = 83  |  train_loss = 0.147201  |  val_loss = 0.152479  |  training_for: 122.99
epoch = 84  |  train_loss = 0.147241  |  val_loss = 0.153068  |  training_for: 124.45
epoch = 85  |  train_loss = 0.147234  |  val_loss = 0.153444  |  training_for: 125.91
epoch = 86  |  train_loss = 0.147228  |  val_loss = 0.152335  |  training_for: 127.35
epoch = 87  |  train_loss = 0.147230  |  val_loss = 0.154037  |  training_for: 128.80
epoch = 88  |  train_loss = 0.147231  |  val_loss = 0.152810  |  training_for: 130.24
epoch = 89  |  train_loss = 0.147196  |  val_loss = 0.152542  |  training_for: 131.69
epoch = 90  |  train_loss = 0.147189  |  val_loss = 0.153177  |  training_for: 133.14
epoch = 91  |  train_loss = 0.147207  |  val_loss = 0.152920  |  training_for: 134.68
epoch = 92  |  train_loss = 0.147176  |  val_loss = 0.153140  |  training_for: 136.13
epoch = 93  |  train_loss = 0.147197  |  val_loss = 0.152315  |  training_for: 137.58
epoch = 94  |  train_loss = 0.147231  |  val_loss = 0.152337  |  training_for: 139.03
epoch = 95  |  train_loss = 0.147199  |  val_loss = 0.153564  |  training_for: 140.50
epoch = 96  |  train_loss = 0.147174  |  val_loss = 0.152779  |  training_for: 141.95
epoch = 97  |  train_loss = 0.147190  |  val_loss = 0.152951  |  training_for: 143.39
epoch = 98  |  train_loss = 0.147216  |  val_loss = 0.153826  |  training_for: 144.84
epoch = 99  |  train_loss = 0.147226  |  val_loss = 0.152990  |  training_for: 146.29
epoch = 100  |  train_loss = 0.147229  |  val_loss = 0.153613  |  training_for: 147.74
epoch = 101  |  train_loss = 0.147215  |  val_loss = 0.152230  |  training_for: 149.19
epoch = 102  |  train_loss = 0.147222  |  val_loss = 0.153158  |  training_for: 150.65
epoch = 103  |  train_loss = 0.147209  |  val_loss = 0.152958  |  training_for: 152.10
epoch = 104  |  train_loss = 0.147197  |  val_loss = 0.152950  |  training_for: 153.65
epoch = 105  |  train_loss = 0.147203  |  val_loss = 0.153754  |  training_for: 155.09
epoch = 106  |  train_loss = 0.147210  |  val_loss = 0.152972  |  training_for: 156.55
epoch = 107  |  train_loss = 0.147218  |  val_loss = 0.153193  |  training_for: 157.99
epoch = 108  |  train_loss = 0.147205  |  val_loss = 0.153667  |  training_for: 159.43
epoch = 109  |  train_loss = 0.147172  |  val_loss = 0.152452  |  training_for: 160.88
epoch = 110  |  train_loss = 0.147192  |  val_loss = 0.153009  |  training_for: 162.33
epoch = 111  |  train_loss = 0.147150  |  val_loss = 0.153194  |  training_for: 163.78
epoch = 112  |  train_loss = 0.147166  |  val_loss = 0.152830  |  training_for: 165.24
epoch = 113  |  train_loss = 0.147205  |  val_loss = 0.153287  |  training_for: 166.70
epoch = 114  |  train_loss = 0.147202  |  val_loss = 0.153423  |  training_for: 168.17
epoch = 115  |  train_loss = 0.147195  |  val_loss = 0.153176  |  training_for: 169.62
epoch = 116  |  train_loss = 0.147205  |  val_loss = 0.153808  |  training_for: 171.08
epoch = 117  |  train_loss = 0.147190  |  val_loss = 0.152712  |  training_for: 172.54
epoch = 118  |  train_loss = 0.147188  |  val_loss = 0.153620  |  training_for: 174.10
epoch = 119  |  train_loss = 0.147245  |  val_loss = 0.153013  |  training_for: 175.55
epoch = 120  |  train_loss = 0.147219  |  val_loss = 0.152952  |  training_for: 177.00
epoch = 121  |  train_loss = 0.147198  |  val_loss = 0.153611  |  training_for: 178.45
epoch = 122  |  train_loss = 0.147201  |  val_loss = 0.152777  |  training_for: 179.90
epoch = 123  |  train_loss = 0.147183  |  val_loss = 0.153756  |  training_for: 181.37
epoch = 124  |  train_loss = 0.147176  |  val_loss = 0.153535  |  training_for: 182.83
epoch = 125  |  train_loss = 0.147183  |  val_loss = 0.152928  |  training_for: 184.32
epoch = 126  |  train_loss = 0.147199  |  val_loss = 0.152771  |  training_for: 185.81
epoch = 127  |  train_loss = 0.147189  |  val_loss = 0.153468  |  training_for: 187.31
epoch = 128  |  train_loss = 0.147182  |  val_loss = 0.153091  |  training_for: 188.75
epoch = 129  |  train_loss = 0.147176  |  val_loss = 0.153331  |  training_for: 190.21
epoch = 130  |  train_loss = 0.147183  |  val_loss = 0.153604  |  training_for: 191.65
epoch = 131  |  train_loss = 0.147188  |  val_loss = 0.152902  |  training_for: 193.17
epoch = 132  |  train_loss = 0.147160  |  val_loss = 0.153322  |  training_for: 194.72
epoch = 133  |  train_loss = 0.147183  |  val_loss = 0.152583  |  training_for: 196.19
epoch = 134  |  train_loss = 0.147177  |  val_loss = 0.152999  |  training_for: 197.64
epoch = 135  |  train_loss = 0.147184  |  val_loss = 0.153604  |  training_for: 199.10
epoch = 136  |  train_loss = 0.147194  |  val_loss = 0.153201  |  training_for: 200.56
epoch = 137  |  train_loss = 0.147205  |  val_loss = 0.152823  |  training_for: 202.03
epoch = 138  |  train_loss = 0.147183  |  val_loss = 0.152705  |  training_for: 203.49
epoch = 139  |  train_loss = 0.147165  |  val_loss = 0.153315  |  training_for: 204.95
epoch = 140  |  train_loss = 0.147142  |  val_loss = 0.152633  |  training_for: 206.41
epoch = 141  |  train_loss = 0.147137  |  val_loss = 0.153304  |  training_for: 207.91
epoch = 142  |  train_loss = 0.147157  |  val_loss = 0.153847  |  training_for: 209.38
epoch = 143  |  train_loss = 0.147165  |  val_loss = 0.153114  |  training_for: 210.86
epoch = 144  |  train_loss = 0.147176  |  val_loss = 0.153607  |  training_for: 212.32
epoch = 145  |  train_loss = 0.147176  |  val_loss = 0.152956  |  training_for: 213.88
epoch = 146  |  train_loss = 0.147153  |  val_loss = 0.152966  |  training_for: 215.34
epoch = 147  |  train_loss = 0.147153  |  val_loss = 0.153357  |  training_for: 216.80
epoch = 148  |  train_loss = 0.147175  |  val_loss = 0.153091  |  training_for: 218.26
epoch = 149  |  train_loss = 0.147173  |  val_loss = 0.153315  |  training_for: 219.73
epoch = 150  |  train_loss = 0.147163  |  val_loss = 0.153391  |  training_for: 221.21
Traceback (most recent call last):
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 127, in <module>
    main()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 114, in main
    train(model = model,
  File "/home/jwilkie/code_base/packages/model_training/training_loops.py", line 142, in train
    for batch_num, batch in enumerate(val_dl):
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 678, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
KeyboardInterrupt