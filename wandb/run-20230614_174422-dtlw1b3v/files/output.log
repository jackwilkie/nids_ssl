epoch = 0  |  train_loss = 0.106896  |  val_loss = 0.095352  |  training_for: 1.34
epoch = 1  |  train_loss = 0.104839  |  val_loss = 0.094001  |  training_for: 2.33
epoch = 2  |  train_loss = 0.102305  |  val_loss = 0.092372  |  training_for: 3.37
epoch = 3  |  train_loss = 0.099840  |  val_loss = 0.091011  |  training_for: 4.34
epoch = 4  |  train_loss = 0.097912  |  val_loss = 0.089990  |  training_for: 5.32
epoch = 5  |  train_loss = 0.096344  |  val_loss = 0.089206  |  training_for: 6.29
epoch = 6  |  train_loss = 0.095134  |  val_loss = 0.088557  |  training_for: 7.28
epoch = 7  |  train_loss = 0.094092  |  val_loss = 0.088142  |  training_for: 8.28
epoch = 8  |  train_loss = 0.093365  |  val_loss = 0.088183  |  training_for: 9.36
epoch = 9  |  train_loss = 0.092921  |  val_loss = 0.088106  |  training_for: 10.35
epoch = 10  |  train_loss = 0.092596  |  val_loss = 0.088049  |  training_for: 11.35
epoch = 11  |  train_loss = 0.092344  |  val_loss = 0.087920  |  training_for: 12.33
epoch = 12  |  train_loss = 0.092133  |  val_loss = 0.087775  |  training_for: 13.32
epoch = 13  |  train_loss = 0.091940  |  val_loss = 0.087854  |  training_for: 14.30
epoch = 14  |  train_loss = 0.091770  |  val_loss = 0.087901  |  training_for: 15.30
epoch = 15  |  train_loss = 0.091635  |  val_loss = 0.088015  |  training_for: 16.40
epoch = 16  |  train_loss = 0.091529  |  val_loss = 0.088190  |  training_for: 17.38
epoch = 17  |  train_loss = 0.091420  |  val_loss = 0.088123  |  training_for: 18.36
epoch = 18  |  train_loss = 0.091336  |  val_loss = 0.088018  |  training_for: 19.34
epoch = 19  |  train_loss = 0.091265  |  val_loss = 0.088043  |  training_for: 20.33
epoch = 20  |  train_loss = 0.091203  |  val_loss = 0.087946  |  training_for: 21.33
epoch = 21  |  train_loss = 0.091152  |  val_loss = 0.087860  |  training_for: 22.31
epoch = 22  |  train_loss = 0.091102  |  val_loss = 0.087783  |  training_for: 23.30
epoch = 23  |  train_loss = 0.091069  |  val_loss = 0.087738  |  training_for: 24.28
epoch = 24  |  train_loss = 0.091024  |  val_loss = 0.087870  |  training_for: 25.26
epoch = 25  |  train_loss = 0.090988  |  val_loss = 0.087803  |  training_for: 26.35
epoch = 26  |  train_loss = 0.090956  |  val_loss = 0.087694  |  training_for: 27.32
epoch = 27  |  train_loss = 0.090937  |  val_loss = 0.087830  |  training_for: 28.30
epoch = 28  |  train_loss = 0.090907  |  val_loss = 0.087752  |  training_for: 29.28
epoch = 29  |  train_loss = 0.090875  |  val_loss = 0.087804  |  training_for: 30.26
epoch = 30  |  train_loss = 0.090860  |  val_loss = 0.087833  |  training_for: 31.22
epoch = 31  |  train_loss = 0.090832  |  val_loss = 0.087769  |  training_for: 32.18
epoch = 32  |  train_loss = 0.090812  |  val_loss = 0.087924  |  training_for: 33.16
epoch = 33  |  train_loss = 0.090791  |  val_loss = 0.087790  |  training_for: 34.14
epoch = 34  |  train_loss = 0.090767  |  val_loss = 0.087932  |  training_for: 35.11
epoch = 35  |  train_loss = 0.090747  |  val_loss = 0.087888  |  training_for: 36.10
epoch = 36  |  train_loss = 0.090723  |  val_loss = 0.087817  |  training_for: 37.17
epoch = 37  |  train_loss = 0.090693  |  val_loss = 0.088004  |  training_for: 38.16
epoch = 38  |  train_loss = 0.090658  |  val_loss = 0.087973  |  training_for: 39.14
epoch = 39  |  train_loss = 0.090630  |  val_loss = 0.087702  |  training_for: 40.13
epoch = 40  |  train_loss = 0.090597  |  val_loss = 0.087860  |  training_for: 41.12
epoch = 41  |  train_loss = 0.090572  |  val_loss = 0.087896  |  training_for: 42.10
epoch = 42  |  train_loss = 0.090548  |  val_loss = 0.087860  |  training_for: 43.08
epoch = 43  |  train_loss = 0.090531  |  val_loss = 0.087831  |  training_for: 44.17
epoch = 44  |  train_loss = 0.090511  |  val_loss = 0.087864  |  training_for: 45.14
epoch = 45  |  train_loss = 0.090495  |  val_loss = 0.087822  |  training_for: 46.13
epoch = 46  |  train_loss = 0.090476  |  val_loss = 0.087777  |  training_for: 47.11
epoch = 47  |  train_loss = 0.090469  |  val_loss = 0.087774  |  training_for: 48.08
epoch = 48  |  train_loss = 0.090450  |  val_loss = 0.087736  |  training_for: 49.06
epoch = 49  |  train_loss = 0.090442  |  val_loss = 0.087842  |  training_for: 50.09
epoch = 50  |  train_loss = 0.090428  |  val_loss = 0.087784  |  training_for: 51.08
epoch = 51  |  train_loss = 0.090434  |  val_loss = 0.087778  |  training_for: 52.04
epoch = 52  |  train_loss = 0.090422  |  val_loss = 0.087772  |  training_for: 53.02
epoch = 53  |  train_loss = 0.090407  |  val_loss = 0.087940  |  training_for: 54.01
epoch = 54  |  train_loss = 0.090402  |  val_loss = 0.087824  |  training_for: 55.08
epoch = 55  |  train_loss = 0.090392  |  val_loss = 0.087875  |  training_for: 56.05
epoch = 56  |  train_loss = 0.090395  |  val_loss = 0.087809  |  training_for: 57.02
epoch = 57  |  train_loss = 0.090381  |  val_loss = 0.087988  |  training_for: 58.00
epoch = 58  |  train_loss = 0.090374  |  val_loss = 0.087883  |  training_for: 58.98
epoch = 59  |  train_loss = 0.090370  |  val_loss = 0.087801  |  training_for: 59.96
epoch = 60  |  train_loss = 0.090365  |  val_loss = 0.088033  |  training_for: 60.94
epoch = 61  |  train_loss = 0.090364  |  val_loss = 0.087853  |  training_for: 62.02
epoch = 62  |  train_loss = 0.090353  |  val_loss = 0.088052  |  training_for: 63.00
epoch = 63  |  train_loss = 0.090351  |  val_loss = 0.087955  |  training_for: 63.98
epoch = 64  |  train_loss = 0.090352  |  val_loss = 0.087890  |  training_for: 64.96
epoch = 65  |  train_loss = 0.090343  |  val_loss = 0.087845  |  training_for: 65.95
epoch = 66  |  train_loss = 0.090343  |  val_loss = 0.088014  |  training_for: 66.95
epoch = 67  |  train_loss = 0.090334  |  val_loss = 0.088054  |  training_for: 67.93
epoch = 68  |  train_loss = 0.090330  |  val_loss = 0.087937  |  training_for: 68.92
epoch = 69  |  train_loss = 0.090328  |  val_loss = 0.087914  |  training_for: 69.91
epoch = 70  |  train_loss = 0.090323  |  val_loss = 0.088029  |  training_for: 70.88
epoch = 71  |  train_loss = 0.090335  |  val_loss = 0.087993  |  training_for: 71.88
epoch = 72  |  train_loss = 0.090324  |  val_loss = 0.088087  |  training_for: 72.95
epoch = 73  |  train_loss = 0.090323  |  val_loss = 0.088148  |  training_for: 73.94
epoch = 74  |  train_loss = 0.090313  |  val_loss = 0.088012  |  training_for: 74.92
epoch = 75  |  train_loss = 0.090311  |  val_loss = 0.088211  |  training_for: 75.93
epoch = 76  |  train_loss = 0.090310  |  val_loss = 0.088121  |  training_for: 76.91
epoch = 77  |  train_loss = 0.090302  |  val_loss = 0.088220  |  training_for: 77.88
epoch = 78  |  train_loss = 0.090302  |  val_loss = 0.087966  |  training_for: 78.86
epoch = 79  |  train_loss = 0.090308  |  val_loss = 0.088133  |  training_for: 79.92
epoch = 80  |  train_loss = 0.090293  |  val_loss = 0.088232  |  training_for: 80.89
epoch = 81  |  train_loss = 0.090293  |  val_loss = 0.088270  |  training_for: 81.91
epoch = 82  |  train_loss = 0.090292  |  val_loss = 0.088172  |  training_for: 82.89
epoch = 83  |  train_loss = 0.090291  |  val_loss = 0.087981  |  training_for: 83.87
epoch = 84  |  train_loss = 0.090286  |  val_loss = 0.088496  |  training_for: 84.84
epoch = 85  |  train_loss = 0.090288  |  val_loss = 0.088045  |  training_for: 85.83
epoch = 86  |  train_loss = 0.090292  |  val_loss = 0.088461  |  training_for: 86.82
epoch = 87  |  train_loss = 0.090283  |  val_loss = 0.088242  |  training_for: 87.79
epoch = 88  |  train_loss = 0.090287  |  val_loss = 0.088427  |  training_for: 88.77
epoch = 89  |  train_loss = 0.090286  |  val_loss = 0.088296  |  training_for: 89.74
epoch = 90  |  train_loss = 0.090274  |  val_loss = 0.088243  |  training_for: 90.82
epoch = 91  |  train_loss = 0.090265  |  val_loss = 0.088272  |  training_for: 91.79
epoch = 92  |  train_loss = 0.090267  |  val_loss = 0.088342  |  training_for: 92.77
epoch = 93  |  train_loss = 0.090260  |  val_loss = 0.088324  |  training_for: 93.75
epoch = 94  |  train_loss = 0.090266  |  val_loss = 0.088385  |  training_for: 94.78
epoch = 95  |  train_loss = 0.090263  |  val_loss = 0.088391  |  training_for: 95.75
epoch = 96  |  train_loss = 0.090262  |  val_loss = 0.088240  |  training_for: 96.74
epoch = 97  |  train_loss = 0.090264  |  val_loss = 0.088459  |  training_for: 97.81
epoch = 98  |  train_loss = 0.090259  |  val_loss = 0.088509  |  training_for: 98.80
epoch = 99  |  train_loss = 0.090258  |  val_loss = 0.088411  |  training_for: 99.79
epoch = 100  |  train_loss = 0.090254  |  val_loss = 0.088521  |  training_for: 100.77
epoch = 101  |  train_loss = 0.090252  |  val_loss = 0.088391  |  training_for: 101.76
epoch = 102  |  train_loss = 0.090256  |  val_loss = 0.088577  |  training_for: 102.73
epoch = 103  |  train_loss = 0.090247  |  val_loss = 0.088401  |  training_for: 103.71
epoch = 104  |  train_loss = 0.090251  |  val_loss = 0.088666  |  training_for: 104.69
epoch = 105  |  train_loss = 0.090248  |  val_loss = 0.088424  |  training_for: 105.67
epoch = 106  |  train_loss = 0.090248  |  val_loss = 0.088441  |  training_for: 106.65
epoch = 107  |  train_loss = 0.090247  |  val_loss = 0.088608  |  training_for: 107.62
epoch = 108  |  train_loss = 0.090244  |  val_loss = 0.088476  |  training_for: 108.70
epoch = 109  |  train_loss = 0.090238  |  val_loss = 0.088428  |  training_for: 109.68
epoch = 110  |  train_loss = 0.090241  |  val_loss = 0.088628  |  training_for: 110.66
epoch = 111  |  train_loss = 0.090239  |  val_loss = 0.088529  |  training_for: 111.67
epoch = 112  |  train_loss = 0.090232  |  val_loss = 0.088437  |  training_for: 112.66
epoch = 113  |  train_loss = 0.090237  |  val_loss = 0.088590  |  training_for: 113.65
epoch = 114  |  train_loss = 0.090238  |  val_loss = 0.088416  |  training_for: 114.73
epoch = 115  |  train_loss = 0.090234  |  val_loss = 0.088674  |  training_for: 115.71
epoch = 116  |  train_loss = 0.090237  |  val_loss = 0.088466  |  training_for: 116.70
epoch = 117  |  train_loss = 0.090229  |  val_loss = 0.088525  |  training_for: 117.66
epoch = 118  |  train_loss = 0.090232  |  val_loss = 0.088676  |  training_for: 118.64
epoch = 119  |  train_loss = 0.090225  |  val_loss = 0.088553  |  training_for: 119.63
epoch = 120  |  train_loss = 0.090226  |  val_loss = 0.088367  |  training_for: 120.62
epoch = 121  |  train_loss = 0.090225  |  val_loss = 0.088745  |  training_for: 121.61
epoch = 122  |  train_loss = 0.090225  |  val_loss = 0.088578  |  training_for: 122.58
epoch = 123  |  train_loss = 0.090220  |  val_loss = 0.088625  |  training_for: 123.56
epoch = 124  |  train_loss = 0.090232  |  val_loss = 0.088757  |  training_for: 124.55
epoch = 125  |  train_loss = 0.090224  |  val_loss = 0.088404  |  training_for: 125.54
epoch = 126  |  train_loss = 0.090234  |  val_loss = 0.088857  |  training_for: 126.61
epoch = 127  |  train_loss = 0.090227  |  val_loss = 0.088587  |  training_for: 127.60
epoch = 128  |  train_loss = 0.090221  |  val_loss = 0.088767  |  training_for: 128.58
epoch = 129  |  train_loss = 0.090224  |  val_loss = 0.088564  |  training_for: 129.58
epoch = 130  |  train_loss = 0.090223  |  val_loss = 0.088627  |  training_for: 130.55
epoch = 131  |  train_loss = 0.090212  |  val_loss = 0.088650  |  training_for: 131.53
epoch = 132  |  train_loss = 0.090215  |  val_loss = 0.088765  |  training_for: 132.65
epoch = 133  |  train_loss = 0.090210  |  val_loss = 0.088481  |  training_for: 133.63
epoch = 134  |  train_loss = 0.090223  |  val_loss = 0.088730  |  training_for: 134.62
epoch = 135  |  train_loss = 0.090220  |  val_loss = 0.088828  |  training_for: 135.61
epoch = 136  |  train_loss = 0.090216  |  val_loss = 0.088618  |  training_for: 136.58
epoch = 137  |  train_loss = 0.090216  |  val_loss = 0.088699  |  training_for: 137.56
epoch = 138  |  train_loss = 0.090215  |  val_loss = 0.088813  |  training_for: 138.56
epoch = 139  |  train_loss = 0.090213  |  val_loss = 0.088655  |  training_for: 139.54
epoch = 140  |  train_loss = 0.090215  |  val_loss = 0.088650  |  training_for: 140.52
epoch = 141  |  train_loss = 0.090210  |  val_loss = 0.088862  |  training_for: 141.49
epoch = 142  |  train_loss = 0.090204  |  val_loss = 0.088706  |  training_for: 142.49
epoch = 143  |  train_loss = 0.090202  |  val_loss = 0.088788  |  training_for: 143.56
epoch = 144  |  train_loss = 0.090218  |  val_loss = 0.088780  |  training_for: 144.55
epoch = 145  |  train_loss = 0.090215  |  val_loss = 0.088821  |  training_for: 145.51
epoch = 146  |  train_loss = 0.090203  |  val_loss = 0.088668  |  training_for: 146.49
epoch = 147  |  train_loss = 0.090211  |  val_loss = 0.088790  |  training_for: 147.48
epoch = 148  |  train_loss = 0.090201  |  val_loss = 0.088834  |  training_for: 148.46
epoch = 149  |  train_loss = 0.090201  |  val_loss = 0.088918  |  training_for: 149.44
epoch = 150  |  train_loss = 0.090205  |  val_loss = 0.088616  |  training_for: 150.54
epoch = 151  |  train_loss = 0.090200  |  val_loss = 0.088828  |  training_for: 151.52
epoch = 152  |  train_loss = 0.090204  |  val_loss = 0.088631  |  training_for: 152.51
epoch = 153  |  train_loss = 0.090197  |  val_loss = 0.088871  |  training_for: 153.49
epoch = 154  |  train_loss = 0.090201  |  val_loss = 0.088680  |  training_for: 154.47
epoch = 155  |  train_loss = 0.090206  |  val_loss = 0.088860  |  training_for: 155.44
epoch = 156  |  train_loss = 0.090199  |  val_loss = 0.088798  |  training_for: 156.42
epoch = 157  |  train_loss = 0.090206  |  val_loss = 0.088899  |  training_for: 157.41
epoch = 158  |  train_loss = 0.090201  |  val_loss = 0.088846  |  training_for: 158.39
epoch = 159  |  train_loss = 0.090193  |  val_loss = 0.088745  |  training_for: 159.40
epoch = 160  |  train_loss = 0.090197  |  val_loss = 0.088969  |  training_for: 160.38
epoch = 161  |  train_loss = 0.090195  |  val_loss = 0.088634  |  training_for: 161.45
epoch = 162  |  train_loss = 0.090189  |  val_loss = 0.088916  |  training_for: 162.44
epoch = 163  |  train_loss = 0.090195  |  val_loss = 0.088752  |  training_for: 163.42
epoch = 164  |  train_loss = 0.090204  |  val_loss = 0.088780  |  training_for: 164.40
epoch = 165  |  train_loss = 0.090200  |  val_loss = 0.088981  |  training_for: 165.40
epoch = 166  |  train_loss = 0.090184  |  val_loss = 0.088726  |  training_for: 166.38
epoch = 167  |  train_loss = 0.090197  |  val_loss = 0.089094  |  training_for: 167.37
epoch = 168  |  train_loss = 0.090193  |  val_loss = 0.088854  |  training_for: 168.44
epoch = 169  |  train_loss = 0.090189  |  val_loss = 0.088856  |  training_for: 169.42
epoch = 170  |  train_loss = 0.090188  |  val_loss = 0.088923  |  training_for: 170.40
epoch = 171  |  train_loss = 0.090184  |  val_loss = 0.088815  |  training_for: 171.38
epoch = 172  |  train_loss = 0.090185  |  val_loss = 0.088904  |  training_for: 172.37
epoch = 173  |  train_loss = 0.090190  |  val_loss = 0.089016  |  training_for: 173.34
epoch = 174  |  train_loss = 0.090183  |  val_loss = 0.088904  |  training_for: 174.32
epoch = 175  |  train_loss = 0.090182  |  val_loss = 0.088947  |  training_for: 175.30
epoch = 176  |  train_loss = 0.090191  |  val_loss = 0.088871  |  training_for: 176.28
epoch = 177  |  train_loss = 0.090181  |  val_loss = 0.089054  |  training_for: 177.27
epoch = 178  |  train_loss = 0.090183  |  val_loss = 0.088797  |  training_for: 178.25
epoch = 179  |  train_loss = 0.090182  |  val_loss = 0.088960  |  training_for: 179.33
epoch = 180  |  train_loss = 0.090179  |  val_loss = 0.088921  |  training_for: 180.32
epoch = 181  |  train_loss = 0.090181  |  val_loss = 0.088977  |  training_for: 181.31
epoch = 182  |  train_loss = 0.090177  |  val_loss = 0.088864  |  training_for: 182.30
epoch = 183  |  train_loss = 0.090186  |  val_loss = 0.089022  |  training_for: 183.29
epoch = 184  |  train_loss = 0.090181  |  val_loss = 0.088853  |  training_for: 184.26
epoch = 185  |  train_loss = 0.090181  |  val_loss = 0.088803  |  training_for: 185.25
epoch = 186  |  train_loss = 0.090181  |  val_loss = 0.089058  |  training_for: 186.32
epoch = 187  |  train_loss = 0.090182  |  val_loss = 0.088932  |  training_for: 187.30
epoch = 188  |  train_loss = 0.090178  |  val_loss = 0.088747  |  training_for: 188.27
epoch = 189  |  train_loss = 0.090180  |  val_loss = 0.089183  |  training_for: 189.24
epoch = 190  |  train_loss = 0.090184  |  val_loss = 0.088581  |  training_for: 190.23
epoch = 191  |  train_loss = 0.090178  |  val_loss = 0.089046  |  training_for: 191.20
epoch = 192  |  train_loss = 0.090182  |  val_loss = 0.089025  |  training_for: 192.18
epoch = 193  |  train_loss = 0.090174  |  val_loss = 0.088799  |  training_for: 193.16
epoch = 194  |  train_loss = 0.090174  |  val_loss = 0.088777  |  training_for: 194.13
epoch = 195  |  train_loss = 0.090171  |  val_loss = 0.089174  |  training_for: 195.13
epoch = 196  |  train_loss = 0.090178  |  val_loss = 0.088839  |  training_for: 196.19
epoch = 197  |  train_loss = 0.090186  |  val_loss = 0.088747  |  training_for: 197.16
epoch = 198  |  train_loss = 0.090172  |  val_loss = 0.088943  |  training_for: 198.16
epoch = 199  |  train_loss = 0.090173  |  val_loss = 0.088876  |  training_for: 199.13
epoch = 200  |  train_loss = 0.090174  |  val_loss = 0.089022  |  training_for: 200.14
epoch = 201  |  train_loss = 0.090173  |  val_loss = 0.088837  |  training_for: 201.13
epoch = 202  |  train_loss = 0.090180  |  val_loss = 0.088955  |  training_for: 202.11
epoch = 203  |  train_loss = 0.090181  |  val_loss = 0.088871  |  training_for: 203.12
epoch = 204  |  train_loss = 0.090169  |  val_loss = 0.089063  |  training_for: 204.09
epoch = 205  |  train_loss = 0.090171  |  val_loss = 0.088791  |  training_for: 205.07
epoch = 206  |  train_loss = 0.090180  |  val_loss = 0.089017  |  training_for: 206.10
epoch = 207  |  train_loss = 0.090177  |  val_loss = 0.088827  |  training_for: 207.18
epoch = 208  |  train_loss = 0.090164  |  val_loss = 0.089021  |  training_for: 208.17
epoch = 209  |  train_loss = 0.090162  |  val_loss = 0.088955  |  training_for: 209.16
epoch = 210  |  train_loss = 0.090168  |  val_loss = 0.088762  |  training_for: 210.16
epoch = 211  |  train_loss = 0.090160  |  val_loss = 0.088974  |  training_for: 211.17
epoch = 212  |  train_loss = 0.090159  |  val_loss = 0.088963  |  training_for: 212.15
epoch = 213  |  train_loss = 0.090164  |  val_loss = 0.088917  |  training_for: 213.14
epoch = 214  |  train_loss = 0.090163  |  val_loss = 0.088864  |  training_for: 214.22
epoch = 215  |  train_loss = 0.090158  |  val_loss = 0.088936  |  training_for: 215.20
epoch = 216  |  train_loss = 0.090161  |  val_loss = 0.088936  |  training_for: 216.17
epoch = 217  |  train_loss = 0.090162  |  val_loss = 0.088797  |  training_for: 217.16
epoch = 218  |  train_loss = 0.090158  |  val_loss = 0.088797  |  training_for: 218.14
epoch = 219  |  train_loss = 0.090164  |  val_loss = 0.089021  |  training_for: 219.13
epoch = 220  |  train_loss = 0.090161  |  val_loss = 0.088795  |  training_for: 220.11
epoch = 221  |  train_loss = 0.090161  |  val_loss = 0.088908  |  training_for: 221.10
epoch = 222  |  train_loss = 0.090160  |  val_loss = 0.088903  |  training_for: 222.08
epoch = 223  |  train_loss = 0.090162  |  val_loss = 0.088738  |  training_for: 223.07
epoch = 224  |  train_loss = 0.090157  |  val_loss = 0.088968  |  training_for: 224.05
epoch = 225  |  train_loss = 0.090154  |  val_loss = 0.088725  |  training_for: 225.13
epoch = 226  |  train_loss = 0.090159  |  val_loss = 0.089115  |  training_for: 226.11
epoch = 227  |  train_loss = 0.090166  |  val_loss = 0.088851  |  training_for: 227.11
epoch = 228  |  train_loss = 0.090158  |  val_loss = 0.088917  |  training_for: 228.09
epoch = 229  |  train_loss = 0.090154  |  val_loss = 0.089062  |  training_for: 229.05
epoch = 230  |  train_loss = 0.090159  |  val_loss = 0.088688  |  training_for: 230.03
epoch = 231  |  train_loss = 0.090165  |  val_loss = 0.089007  |  training_for: 231.03
epoch = 232  |  train_loss = 0.090155  |  val_loss = 0.089046  |  training_for: 232.10
epoch = 233  |  train_loss = 0.090161  |  val_loss = 0.088990  |  training_for: 233.08
epoch = 234  |  train_loss = 0.090159  |  val_loss = 0.088765  |  training_for: 234.07
epoch = 235  |  train_loss = 0.090159  |  val_loss = 0.088806  |  training_for: 235.04
epoch = 236  |  train_loss = 0.090151  |  val_loss = 0.089055  |  training_for: 236.03
epoch = 237  |  train_loss = 0.090155  |  val_loss = 0.088968  |  training_for: 237.01
epoch = 238  |  train_loss = 0.090154  |  val_loss = 0.088697  |  training_for: 237.98
epoch = 239  |  train_loss = 0.090151  |  val_loss = 0.089059  |  training_for: 238.96
epoch = 240  |  train_loss = 0.090155  |  val_loss = 0.088814  |  training_for: 239.93
epoch = 241  |  train_loss = 0.090156  |  val_loss = 0.088981  |  training_for: 240.92
epoch = 242  |  train_loss = 0.090160  |  val_loss = 0.088897  |  training_for: 241.89
epoch = 243  |  train_loss = 0.090154  |  val_loss = 0.088741  |  training_for: 242.97
epoch = 244  |  train_loss = 0.090153  |  val_loss = 0.088966  |  training_for: 243.95
epoch = 245  |  train_loss = 0.090150  |  val_loss = 0.089059  |  training_for: 244.92
epoch = 246  |  train_loss = 0.090153  |  val_loss = 0.088871  |  training_for: 245.90
epoch = 247  |  train_loss = 0.090154  |  val_loss = 0.089008  |  training_for: 246.88
epoch = 248  |  train_loss = 0.090152  |  val_loss = 0.088896  |  training_for: 247.86
epoch = 249  |  train_loss = 0.090151  |  val_loss = 0.089039  |  training_for: 248.84
epoch = 250  |  train_loss = 0.090149  |  val_loss = 0.088764  |  training_for: 249.92
epoch = 251  |  train_loss = 0.090155  |  val_loss = 0.088864  |  training_for: 250.93
epoch = 252  |  train_loss = 0.090154  |  val_loss = 0.089008  |  training_for: 251.91
epoch = 253  |  train_loss = 0.090152  |  val_loss = 0.088861  |  training_for: 252.89
epoch = 254  |  train_loss = 0.090146  |  val_loss = 0.088942  |  training_for: 253.91
epoch = 255  |  train_loss = 0.090150  |  val_loss = 0.088916  |  training_for: 254.88
epoch = 256  |  train_loss = 0.090147  |  val_loss = 0.088804  |  training_for: 255.87
epoch = 257  |  train_loss = 0.090148  |  val_loss = 0.088959  |  training_for: 256.84
epoch = 258  |  train_loss = 0.090144  |  val_loss = 0.088662  |  training_for: 257.82
epoch = 259  |  train_loss = 0.090149  |  val_loss = 0.088820  |  training_for: 258.81
epoch = 260  |  train_loss = 0.090147  |  val_loss = 0.088928  |  training_for: 259.79
epoch = 261  |  train_loss = 0.090157  |  val_loss = 0.088882  |  training_for: 260.87
epoch = 262  |  train_loss = 0.090151  |  val_loss = 0.088976  |  training_for: 261.84
epoch = 263  |  train_loss = 0.090158  |  val_loss = 0.088835  |  training_for: 262.82
epoch = 264  |  train_loss = 0.090156  |  val_loss = 0.089032  |  training_for: 263.80
epoch = 265  |  train_loss = 0.090147  |  val_loss = 0.088674  |  training_for: 264.78
epoch = 266  |  train_loss = 0.090148  |  val_loss = 0.088954  |  training_for: 265.78
epoch = 267  |  train_loss = 0.090149  |  val_loss = 0.089023  |  training_for: 266.77
epoch = 268  |  train_loss = 0.090146  |  val_loss = 0.088963  |  training_for: 267.84
epoch = 269  |  train_loss = 0.090142  |  val_loss = 0.088755  |  training_for: 268.82
epoch = 270  |  train_loss = 0.090145  |  val_loss = 0.088976  |  training_for: 269.80
epoch = 271  |  train_loss = 0.090146  |  val_loss = 0.088948  |  training_for: 270.80
epoch = 272  |  train_loss = 0.090145  |  val_loss = 0.088837  |  training_for: 271.77
epoch = 273  |  train_loss = 0.090142  |  val_loss = 0.088909  |  training_for: 272.77
epoch = 274  |  train_loss = 0.090147  |  val_loss = 0.089107  |  training_for: 273.75
epoch = 275  |  train_loss = 0.090142  |  val_loss = 0.088725  |  training_for: 274.73
epoch = 276  |  train_loss = 0.090140  |  val_loss = 0.088985  |  training_for: 275.71
epoch = 277  |  train_loss = 0.090142  |  val_loss = 0.088849  |  training_for: 276.68
epoch = 278  |  train_loss = 0.090147  |  val_loss = 0.088963  |  training_for: 277.67
epoch = 279  |  train_loss = 0.090144  |  val_loss = 0.088930  |  training_for: 278.77
epoch = 280  |  train_loss = 0.090146  |  val_loss = 0.088968  |  training_for: 279.74
epoch = 281  |  train_loss = 0.090143  |  val_loss = 0.088700  |  training_for: 280.72
epoch = 282  |  train_loss = 0.090146  |  val_loss = 0.088831  |  training_for: 281.70
epoch = 283  |  train_loss = 0.090145  |  val_loss = 0.088814  |  training_for: 282.67
epoch = 284  |  train_loss = 0.090145  |  val_loss = 0.088772  |  training_for: 283.65
epoch = 285  |  train_loss = 0.090139  |  val_loss = 0.088894  |  training_for: 284.73
epoch = 286  |  train_loss = 0.090144  |  val_loss = 0.088981  |  training_for: 285.70
epoch = 287  |  train_loss = 0.090142  |  val_loss = 0.088960  |  training_for: 286.68
epoch = 288  |  train_loss = 0.090141  |  val_loss = 0.088923  |  training_for: 287.67
epoch = 289  |  train_loss = 0.090143  |  val_loss = 0.088857  |  training_for: 288.65
epoch = 290  |  train_loss = 0.090143  |  val_loss = 0.088935  |  training_for: 289.64
epoch = 291  |  train_loss = 0.090138  |  val_loss = 0.088707  |  training_for: 290.62
epoch = 292  |  train_loss = 0.090142  |  val_loss = 0.089083  |  training_for: 291.60
epoch = 293  |  train_loss = 0.090140  |  val_loss = 0.088684  |  training_for: 292.58
epoch = 294  |  train_loss = 0.090136  |  val_loss = 0.088810  |  training_for: 293.55
epoch = 295  |  train_loss = 0.090137  |  val_loss = 0.088914  |  training_for: 294.53
epoch = 296  |  train_loss = 0.090134  |  val_loss = 0.088830  |  training_for: 295.53
epoch = 297  |  train_loss = 0.090136  |  val_loss = 0.088866  |  training_for: 296.62
epoch = 298  |  train_loss = 0.090135  |  val_loss = 0.088835  |  training_for: 297.61
epoch = 299  |  train_loss = 0.090134  |  val_loss = 0.088967  |  training_for: 298.59
epoch = 300  |  train_loss = 0.090138  |  val_loss = 0.088845  |  training_for: 299.57
epoch = 301  |  train_loss = 0.090137  |  val_loss = 0.088794  |  training_for: 300.56
epoch = 302  |  train_loss = 0.090136  |  val_loss = 0.088701  |  training_for: 301.55
epoch = 303  |  train_loss = 0.090136  |  val_loss = 0.088904  |  training_for: 302.62
epoch = 304  |  train_loss = 0.090139  |  val_loss = 0.088804  |  training_for: 303.64
epoch = 305  |  train_loss = 0.090139  |  val_loss = 0.088667  |  training_for: 304.62
epoch = 306  |  train_loss = 0.090136  |  val_loss = 0.088970  |  training_for: 305.60
epoch = 307  |  train_loss = 0.090138  |  val_loss = 0.088763  |  training_for: 306.59
epoch = 308  |  train_loss = 0.090137  |  val_loss = 0.088778  |  training_for: 307.57
epoch = 309  |  train_loss = 0.090137  |  val_loss = 0.088844  |  training_for: 308.54
epoch = 310  |  train_loss = 0.090135  |  val_loss = 0.088727  |  training_for: 309.53
epoch = 311  |  train_loss = 0.090133  |  val_loss = 0.089105  |  training_for: 310.51
epoch = 312  |  train_loss = 0.090138  |  val_loss = 0.088647  |  training_for: 311.49
epoch = 313  |  train_loss = 0.090130  |  val_loss = 0.088751  |  training_for: 312.49
epoch = 314  |  train_loss = 0.090131  |  val_loss = 0.088925  |  training_for: 313.58
epoch = 315  |  train_loss = 0.090135  |  val_loss = 0.088691  |  training_for: 314.57
epoch = 316  |  train_loss = 0.090127  |  val_loss = 0.088692  |  training_for: 315.55
epoch = 317  |  train_loss = 0.090131  |  val_loss = 0.088761  |  training_for: 316.55
epoch = 318  |  train_loss = 0.090134  |  val_loss = 0.088923  |  training_for: 317.53
epoch = 319  |  train_loss = 0.090138  |  val_loss = 0.088693  |  training_for: 318.51
epoch = 320  |  train_loss = 0.090132  |  val_loss = 0.088782  |  training_for: 319.49
epoch = 321  |  train_loss = 0.090127  |  val_loss = 0.088956  |  training_for: 320.56
epoch = 322  |  train_loss = 0.090125  |  val_loss = 0.088683  |  training_for: 321.56
epoch = 323  |  train_loss = 0.090125  |  val_loss = 0.088699  |  training_for: 322.52
epoch = 324  |  train_loss = 0.090131  |  val_loss = 0.088992  |  training_for: 323.50
epoch = 325  |  train_loss = 0.090129  |  val_loss = 0.088578  |  training_for: 324.48
epoch = 326  |  train_loss = 0.090128  |  val_loss = 0.088769  |  training_for: 325.46
epoch = 327  |  train_loss = 0.090129  |  val_loss = 0.088875  |  training_for: 326.45
epoch = 328  |  train_loss = 0.090122  |  val_loss = 0.088943  |  training_for: 327.42
epoch = 329  |  train_loss = 0.090125  |  val_loss = 0.088705  |  training_for: 328.39
epoch = 330  |  train_loss = 0.090121  |  val_loss = 0.088792  |  training_for: 329.38
epoch = 331  |  train_loss = 0.090126  |  val_loss = 0.088675  |  training_for: 330.35
epoch = 332  |  train_loss = 0.090124  |  val_loss = 0.088782  |  training_for: 331.43
epoch = 333  |  train_loss = 0.090122  |  val_loss = 0.088797  |  training_for: 332.41
epoch = 334  |  train_loss = 0.090121  |  val_loss = 0.088623  |  training_for: 333.38
epoch = 335  |  train_loss = 0.090119  |  val_loss = 0.088821  |  training_for: 334.37
epoch = 336  |  train_loss = 0.090125  |  val_loss = 0.088755  |  training_for: 335.36
epoch = 337  |  train_loss = 0.090121  |  val_loss = 0.088767  |  training_for: 336.32
epoch = 338  |  train_loss = 0.090124  |  val_loss = 0.088705  |  training_for: 337.34
epoch = 339  |  train_loss = 0.090128  |  val_loss = 0.088821  |  training_for: 338.41
epoch = 340  |  train_loss = 0.090127  |  val_loss = 0.088720  |  training_for: 339.42
epoch = 341  |  train_loss = 0.090126  |  val_loss = 0.088848  |  training_for: 340.41
epoch = 342  |  train_loss = 0.090129  |  val_loss = 0.088731  |  training_for: 341.38
epoch = 343  |  train_loss = 0.090140  |  val_loss = 0.088813  |  training_for: 342.37
epoch = 344  |  train_loss = 0.090135  |  val_loss = 0.088961  |  training_for: 343.35
epoch = 345  |  train_loss = 0.090126  |  val_loss = 0.088695  |  training_for: 344.33
epoch = 346  |  train_loss = 0.090128  |  val_loss = 0.088860  |  training_for: 345.30
epoch = 347  |  train_loss = 0.090123  |  val_loss = 0.088715  |  training_for: 346.27
epoch = 348  |  train_loss = 0.090120  |  val_loss = 0.088794  |  training_for: 347.26
epoch = 349  |  train_loss = 0.090129  |  val_loss = 0.088984  |  training_for: 348.23
epoch = 350  |  train_loss = 0.090128  |  val_loss = 0.088678  |  training_for: 349.33
epoch = 351  |  train_loss = 0.090123  |  val_loss = 0.088841  |  training_for: 350.36
epoch = 352  |  train_loss = 0.090122  |  val_loss = 0.088796  |  training_for: 351.34
epoch = 353  |  train_loss = 0.090124  |  val_loss = 0.088672  |  training_for: 352.35
epoch = 354  |  train_loss = 0.090125  |  val_loss = 0.088844  |  training_for: 353.33
epoch = 355  |  train_loss = 0.090123  |  val_loss = 0.088818  |  training_for: 354.31
epoch = 356  |  train_loss = 0.090125  |  val_loss = 0.088771  |  training_for: 355.32
epoch = 357  |  train_loss = 0.090123  |  val_loss = 0.088841  |  training_for: 356.40
epoch = 358  |  train_loss = 0.090124  |  val_loss = 0.088852  |  training_for: 357.40
epoch = 359  |  train_loss = 0.090123  |  val_loss = 0.088513  |  training_for: 358.38
epoch = 360  |  train_loss = 0.090119  |  val_loss = 0.088930  |  training_for: 359.38
epoch = 361  |  train_loss = 0.090121  |  val_loss = 0.088631  |  training_for: 360.40
epoch = 362  |  train_loss = 0.090121  |  val_loss = 0.088666  |  training_for: 361.38
epoch = 363  |  train_loss = 0.090122  |  val_loss = 0.088877  |  training_for: 362.37
epoch = 364  |  train_loss = 0.090119  |  val_loss = 0.088647  |  training_for: 363.35
epoch = 365  |  train_loss = 0.090126  |  val_loss = 0.088890  |  training_for: 364.33
epoch = 366  |  train_loss = 0.090117  |  val_loss = 0.088665  |  training_for: 365.30
epoch = 367  |  train_loss = 0.090121  |  val_loss = 0.088540  |  training_for: 366.36
epoch = 368  |  train_loss = 0.090121  |  val_loss = 0.088938  |  training_for: 367.35
epoch = 369  |  train_loss = 0.090122  |  val_loss = 0.088719  |  training_for: 368.32
epoch = 370  |  train_loss = 0.090117  |  val_loss = 0.088839  |  training_for: 369.30
epoch = 371  |  train_loss = 0.090122  |  val_loss = 0.088887  |  training_for: 370.31
epoch = 372  |  train_loss = 0.090126  |  val_loss = 0.088791  |  training_for: 371.28
epoch = 373  |  train_loss = 0.090128  |  val_loss = 0.088653  |  training_for: 372.26
epoch = 374  |  train_loss = 0.090121  |  val_loss = 0.088770  |  training_for: 373.24
epoch = 375  |  train_loss = 0.090121  |  val_loss = 0.088914  |  training_for: 374.22
epoch = 376  |  train_loss = 0.090124  |  val_loss = 0.088658  |  training_for: 375.22
epoch = 377  |  train_loss = 0.090120  |  val_loss = 0.088865  |  training_for: 376.20
epoch = 378  |  train_loss = 0.090118  |  val_loss = 0.088746  |  training_for: 377.28
epoch = 379  |  train_loss = 0.090122  |  val_loss = 0.088641  |  training_for: 378.26
epoch = 380  |  train_loss = 0.090120  |  val_loss = 0.088900  |  training_for: 379.29
epoch = 381  |  train_loss = 0.090126  |  val_loss = 0.088617  |  training_for: 380.31
epoch = 382  |  train_loss = 0.090116  |  val_loss = 0.088744  |  training_for: 381.29
epoch = 383  |  train_loss = 0.090119  |  val_loss = 0.088858  |  training_for: 382.27
epoch = 384  |  train_loss = 0.090114  |  val_loss = 0.088736  |  training_for: 383.24
epoch = 385  |  train_loss = 0.090112  |  val_loss = 0.088703  |  training_for: 384.31
epoch = 386  |  train_loss = 0.090114  |  val_loss = 0.088927  |  training_for: 385.30
epoch = 387  |  train_loss = 0.090112  |  val_loss = 0.088650  |  training_for: 386.28
epoch = 388  |  train_loss = 0.090119  |  val_loss = 0.088824  |  training_for: 387.28
epoch = 389  |  train_loss = 0.090110  |  val_loss = 0.088762  |  training_for: 388.27
epoch = 390  |  train_loss = 0.090108  |  val_loss = 0.088593  |  training_for: 389.26
epoch = 391  |  train_loss = 0.090114  |  val_loss = 0.088934  |  training_for: 390.25
epoch = 392  |  train_loss = 0.090118  |  val_loss = 0.088648  |  training_for: 391.23
epoch = 393  |  train_loss = 0.090117  |  val_loss = 0.088914  |  training_for: 392.22
epoch = 394  |  train_loss = 0.090127  |  val_loss = 0.088578  |  training_for: 393.20
epoch = 395  |  train_loss = 0.090121  |  val_loss = 0.088548  |  training_for: 394.17
epoch = 396  |  train_loss = 0.090110  |  val_loss = 0.089026  |  training_for: 395.25
epoch = 397  |  train_loss = 0.090118  |  val_loss = 0.088665  |  training_for: 396.23
epoch = 398  |  train_loss = 0.090117  |  val_loss = 0.088528  |  training_for: 397.21
epoch = 399  |  train_loss = 0.090115  |  val_loss = 0.088679  |  training_for: 398.18
epoch = 400  |  train_loss = 0.090115  |  val_loss = 0.089021  |  training_for: 399.17
epoch = 401  |  train_loss = 0.090113  |  val_loss = 0.088539  |  training_for: 400.17
epoch = 402  |  train_loss = 0.090116  |  val_loss = 0.088677  |  training_for: 401.15
epoch = 403  |  train_loss = 0.090113  |  val_loss = 0.088844  |  training_for: 402.22
epoch = 404  |  train_loss = 0.090114  |  val_loss = 0.088583  |  training_for: 403.21
epoch = 405  |  train_loss = 0.090115  |  val_loss = 0.088668  |  training_for: 404.19
epoch = 406  |  train_loss = 0.090115  |  val_loss = 0.088837  |  training_for: 405.17
epoch = 407  |  train_loss = 0.090112  |  val_loss = 0.088610  |  training_for: 406.15
epoch = 408  |  train_loss = 0.090109  |  val_loss = 0.088783  |  training_for: 407.12
epoch = 409  |  train_loss = 0.090111  |  val_loss = 0.088783  |  training_for: 408.10
epoch = 410  |  train_loss = 0.090113  |  val_loss = 0.088726  |  training_for: 409.08
epoch = 411  |  train_loss = 0.090114  |  val_loss = 0.088653  |  training_for: 410.06
epoch = 412  |  train_loss = 0.090110  |  val_loss = 0.088671  |  training_for: 411.04
epoch = 413  |  train_loss = 0.090105  |  val_loss = 0.088689  |  training_for: 412.02
epoch = 414  |  train_loss = 0.090112  |  val_loss = 0.088633  |  training_for: 413.09
epoch = 415  |  train_loss = 0.090116  |  val_loss = 0.088757  |  training_for: 414.07
epoch = 416  |  train_loss = 0.090116  |  val_loss = 0.088713  |  training_for: 415.06
epoch = 417  |  train_loss = 0.090114  |  val_loss = 0.088642  |  training_for: 416.05
epoch = 418  |  train_loss = 0.090115  |  val_loss = 0.088790  |  training_for: 417.03
epoch = 419  |  train_loss = 0.090111  |  val_loss = 0.088786  |  training_for: 418.02
epoch = 420  |  train_loss = 0.090113  |  val_loss = 0.088677  |  training_for: 419.00
epoch = 421  |  train_loss = 0.090114  |  val_loss = 0.088798  |  training_for: 420.11
epoch = 422  |  train_loss = 0.090115  |  val_loss = 0.088809  |  training_for: 421.15
epoch = 423  |  train_loss = 0.090111  |  val_loss = 0.088453  |  training_for: 422.12
epoch = 424  |  train_loss = 0.090117  |  val_loss = 0.088793  |  training_for: 423.11
epoch = 425  |  train_loss = 0.090110  |  val_loss = 0.088669  |  training_for: 424.08
epoch = 426  |  train_loss = 0.090113  |  val_loss = 0.088702  |  training_for: 425.07
epoch = 427  |  train_loss = 0.090109  |  val_loss = 0.088661  |  training_for: 426.05
epoch = 428  |  train_loss = 0.090110  |  val_loss = 0.088651  |  training_for: 427.02
epoch = 429  |  train_loss = 0.090104  |  val_loss = 0.088963  |  training_for: 428.01
epoch = 430  |  train_loss = 0.090108  |  val_loss = 0.088591  |  training_for: 428.99
epoch = 431  |  train_loss = 0.090112  |  val_loss = 0.088640  |  training_for: 429.96
epoch = 432  |  train_loss = 0.090103  |  val_loss = 0.088624  |  training_for: 431.03
epoch = 433  |  train_loss = 0.090108  |  val_loss = 0.088645  |  training_for: 432.01
epoch = 434  |  train_loss = 0.090109  |  val_loss = 0.088725  |  training_for: 433.00
epoch = 435  |  train_loss = 0.090108  |  val_loss = 0.088826  |  training_for: 433.98
epoch = 436  |  train_loss = 0.090107  |  val_loss = 0.088664  |  training_for: 434.96
epoch = 437  |  train_loss = 0.090111  |  val_loss = 0.088598  |  training_for: 435.94
epoch = 438  |  train_loss = 0.090108  |  val_loss = 0.088828  |  training_for: 436.93
epoch = 439  |  train_loss = 0.090108  |  val_loss = 0.088623  |  training_for: 438.02
epoch = 440  |  train_loss = 0.090108  |  val_loss = 0.088599  |  training_for: 438.99
epoch = 441  |  train_loss = 0.090109  |  val_loss = 0.088724  |  training_for: 439.97
epoch = 442  |  train_loss = 0.090106  |  val_loss = 0.088547  |  training_for: 440.95
epoch = 443  |  train_loss = 0.090107  |  val_loss = 0.088583  |  training_for: 441.93
epoch = 444  |  train_loss = 0.090107  |  val_loss = 0.088657  |  training_for: 442.91
epoch = 445  |  train_loss = 0.090105  |  val_loss = 0.088764  |  training_for: 443.88
epoch = 446  |  train_loss = 0.090112  |  val_loss = 0.088503  |  training_for: 444.86
epoch = 447  |  train_loss = 0.090109  |  val_loss = 0.088712  |  training_for: 445.84
epoch = 448  |  train_loss = 0.090109  |  val_loss = 0.088581  |  training_for: 446.82
epoch = 449  |  train_loss = 0.090111  |  val_loss = 0.088664  |  training_for: 447.80
epoch = 450  |  train_loss = 0.090112  |  val_loss = 0.088771  |  training_for: 448.86
epoch = 451  |  train_loss = 0.090109  |  val_loss = 0.088718  |  training_for: 449.83
epoch = 452  |  train_loss = 0.090105  |  val_loss = 0.088530  |  training_for: 450.83
epoch = 453  |  train_loss = 0.090103  |  val_loss = 0.088785  |  training_for: 451.81
epoch = 454  |  train_loss = 0.090103  |  val_loss = 0.088733  |  training_for: 452.79
epoch = 455  |  train_loss = 0.090105  |  val_loss = 0.088568  |  training_for: 453.79
epoch = 456  |  train_loss = 0.090107  |  val_loss = 0.088692  |  training_for: 454.86
epoch = 457  |  train_loss = 0.090107  |  val_loss = 0.088558  |  training_for: 455.82
epoch = 458  |  train_loss = 0.090109  |  val_loss = 0.088778  |  training_for: 456.82
epoch = 459  |  train_loss = 0.090111  |  val_loss = 0.088566  |  training_for: 457.79
epoch = 460  |  train_loss = 0.090111  |  val_loss = 0.088613  |  training_for: 458.76
epoch = 461  |  train_loss = 0.090112  |  val_loss = 0.088640  |  training_for: 459.74
epoch = 462  |  train_loss = 0.090108  |  val_loss = 0.088607  |  training_for: 460.74
epoch = 463  |  train_loss = 0.090107  |  val_loss = 0.088552  |  training_for: 461.71
epoch = 464  |  train_loss = 0.090106  |  val_loss = 0.088636  |  training_for: 462.69
epoch = 465  |  train_loss = 0.090110  |  val_loss = 0.088659  |  training_for: 463.69
epoch = 466  |  train_loss = 0.090107  |  val_loss = 0.088537  |  training_for: 464.66
epoch = 467  |  train_loss = 0.090106  |  val_loss = 0.088653  |  training_for: 465.66
epoch = 468  |  train_loss = 0.090106  |  val_loss = 0.088621  |  training_for: 466.74
epoch = 469  |  train_loss = 0.090100  |  val_loss = 0.088642  |  training_for: 467.71
epoch = 470  |  train_loss = 0.090106  |  val_loss = 0.088564  |  training_for: 468.69
epoch = 471  |  train_loss = 0.090103  |  val_loss = 0.088680  |  training_for: 469.68
epoch = 472  |  train_loss = 0.090107  |  val_loss = 0.088730  |  training_for: 470.65
epoch = 473  |  train_loss = 0.090100  |  val_loss = 0.088709  |  training_for: 471.63
epoch = 474  |  train_loss = 0.090102  |  val_loss = 0.088470  |  training_for: 472.70
epoch = 475  |  train_loss = 0.090101  |  val_loss = 0.088669  |  training_for: 473.68
epoch = 476  |  train_loss = 0.090102  |  val_loss = 0.088854  |  training_for: 474.65
Traceback (most recent call last):
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 131, in <module>
    main()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 117, in main
    train(model = model,
  File "/home/jwilkie/code_base/packages/model_training/training_loops.py", line 150, in train
    loss = loss_calc(model, batch)  #compute validation loss
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/saint/composite_loss.py", line 46, in calc_loss
    z_aug = model.feed_aug(x)
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/saint/saint.py", line 141, in feed_aug
    return self.encoder(self.latent_aug(self.embedding_layer(self.feature_aug(x))))
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/augmentations.py", line 94, in forward
    return self.layers(x)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/augmentations.py", line 54, in forward
    return self.augment(x)
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/augmentations.py", line 187, in augment
    noise_mask = noise * self.get_aug_matrix(x)
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/augmentations.py", line 71, in get_aug_matrix
    sample_mask = T.bernoulli(prob_matrix).unsqueeze(-1)
KeyboardInterrupt