epoch = 0  |  train_loss = 0.152249  |  val_loss = 0.151928  |  training_for: 1.77
epoch = 1  |  train_loss = 0.136179  |  val_loss = 0.154519  |  training_for: 3.21
epoch = 2  |  train_loss = 0.134666  |  val_loss = 0.155352  |  training_for: 4.63
epoch = 3  |  train_loss = 0.134150  |  val_loss = 0.156443  |  training_for: 6.06
epoch = 4  |  train_loss = 0.133842  |  val_loss = 0.154833  |  training_for: 7.48
epoch = 5  |  train_loss = 0.133761  |  val_loss = 0.157036  |  training_for: 8.91
Traceback (most recent call last):
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 127, in <module>
    main()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 114, in main
    train(model = model,
  File "/home/jwilkie/code_base/packages/model_training/training_loops.py", line 144, in train
    loss = loss_calc(model, batch)  #compute validation loss
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/saint/composite_loss.py", line 45, in calc_loss
    z = model.feed(x)
  File "/home/jwilkie/code_base/packages/self_supervised/tabular/saint/saint.py", line 138, in feed
    return self.encoder(self.embedding_layer(x))
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/encoders.py", line 55, in forward
    x = layer(x)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/encoders.py", line 104, in forward
    return self.sublayers[1](x, self.feed_forward)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/architecture.py", line 45, in forward
    return x + self.dropout(sublayer(self.norm(x)))
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/custom_transformers/architecture.py", line 135, in forward
    return self.w2(self.dropout(self.activation(self.w1(x))))  # apply forward pass
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/code_base/packages/utils/activations.py", line 32, in forward
    x = self.linear_layer(x)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1601, in __getattr__
    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
KeyboardInterrupt