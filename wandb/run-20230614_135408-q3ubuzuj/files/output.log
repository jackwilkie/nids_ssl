epoch = 0  |  train_loss = 0.165582  |  val_loss = 0.164113  |  training_for: 1.79
epoch = 1  |  train_loss = 0.155589  |  val_loss = 0.162705  |  training_for: 3.21
epoch = 2  |  train_loss = 0.152356  |  val_loss = 0.163533  |  training_for: 4.63
epoch = 3  |  train_loss = 0.150911  |  val_loss = 0.164113  |  training_for: 6.05
epoch = 4  |  train_loss = 0.150129  |  val_loss = 0.163926  |  training_for: 7.46
epoch = 5  |  train_loss = 0.149600  |  val_loss = 0.163641  |  training_for: 8.91
epoch = 6  |  train_loss = 0.149273  |  val_loss = 0.162817  |  training_for: 10.34
epoch = 7  |  train_loss = 0.149070  |  val_loss = 0.162642  |  training_for: 11.76
epoch = 8  |  train_loss = 0.148924  |  val_loss = 0.163026  |  training_for: 13.19
epoch = 9  |  train_loss = 0.148856  |  val_loss = 0.162743  |  training_for: 14.62
epoch = 10  |  train_loss = 0.148774  |  val_loss = 0.163179  |  training_for: 16.16
epoch = 11  |  train_loss = 0.148703  |  val_loss = 0.162481  |  training_for: 17.58
epoch = 12  |  train_loss = 0.148637  |  val_loss = 0.161679  |  training_for: 19.00
epoch = 13  |  train_loss = 0.148633  |  val_loss = 0.162023  |  training_for: 20.43
epoch = 14  |  train_loss = 0.148590  |  val_loss = 0.163223  |  training_for: 21.85
epoch = 15  |  train_loss = 0.148586  |  val_loss = 0.162066  |  training_for: 23.25
epoch = 16  |  train_loss = 0.148527  |  val_loss = 0.163008  |  training_for: 24.68
epoch = 17  |  train_loss = 0.148500  |  val_loss = 0.162222  |  training_for: 26.10
epoch = 18  |  train_loss = 0.148468  |  val_loss = 0.161570  |  training_for: 27.56
epoch = 19  |  train_loss = 0.148469  |  val_loss = 0.161256  |  training_for: 28.97
epoch = 20  |  train_loss = 0.148446  |  val_loss = 0.161659  |  training_for: 30.40
epoch = 21  |  train_loss = 0.148422  |  val_loss = 0.162074  |  training_for: 31.83
epoch = 22  |  train_loss = 0.148415  |  val_loss = 0.161204  |  training_for: 33.26
epoch = 23  |  train_loss = 0.148437  |  val_loss = 0.160751  |  training_for: 34.78
epoch = 24  |  train_loss = 0.148479  |  val_loss = 0.160493  |  training_for: 36.24
epoch = 25  |  train_loss = 0.148443  |  val_loss = 0.160906  |  training_for: 37.66
epoch = 26  |  train_loss = 0.148380  |  val_loss = 0.161363  |  training_for: 39.07
epoch = 27  |  train_loss = 0.148374  |  val_loss = 0.161540  |  training_for: 40.51
epoch = 28  |  train_loss = 0.148369  |  val_loss = 0.158996  |  training_for: 41.94
epoch = 29  |  train_loss = 0.148387  |  val_loss = 0.160226  |  training_for: 43.37
epoch = 30  |  train_loss = 0.148354  |  val_loss = 0.161301  |  training_for: 44.80
epoch = 31  |  train_loss = 0.148342  |  val_loss = 0.161404  |  training_for: 46.24
epoch = 32  |  train_loss = 0.148336  |  val_loss = 0.160873  |  training_for: 47.66
epoch = 33  |  train_loss = 0.148349  |  val_loss = 0.160418  |  training_for: 49.09
epoch = 34  |  train_loss = 0.148298  |  val_loss = 0.160485  |  training_for: 50.51
epoch = 35  |  train_loss = 0.148292  |  val_loss = 0.159863  |  training_for: 51.95
epoch = 36  |  train_loss = 0.148322  |  val_loss = 0.160753  |  training_for: 53.47
epoch = 37  |  train_loss = 0.148284  |  val_loss = 0.160133  |  training_for: 54.91
epoch = 38  |  train_loss = 0.148319  |  val_loss = 0.161344  |  training_for: 56.34
epoch = 39  |  train_loss = 0.148330  |  val_loss = 0.159772  |  training_for: 57.78
epoch = 40  |  train_loss = 0.148319  |  val_loss = 0.160365  |  training_for: 59.19
epoch = 41  |  train_loss = 0.148288  |  val_loss = 0.161843  |  training_for: 60.60
epoch = 42  |  train_loss = 0.148259  |  val_loss = 0.160586  |  training_for: 62.00
epoch = 43  |  train_loss = 0.148253  |  val_loss = 0.160682  |  training_for: 63.42
epoch = 44  |  train_loss = 0.148264  |  val_loss = 0.160457  |  training_for: 64.83
epoch = 45  |  train_loss = 0.148255  |  val_loss = 0.160493  |  training_for: 66.25
Traceback (most recent call last):
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 127, in <module>
    main()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/jwilkie/code_base/nids_ssl/main.py", line 114, in main
    train(model = model,
  File "/home/jwilkie/code_base/packages/model_training/training_loops.py", line 142, in train
    for batch_num, batch in enumerate(val_dl):
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 678, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jwilkie/pylabs/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
KeyboardInterrupt